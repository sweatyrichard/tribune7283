{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0477d2c0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sweatyrichard/tribune7283.git"
      ],
      "metadata": {
        "id": "F6iOQScQaudV",
        "outputId": "a57a4643-512a-4867-e8df-0591bda6b179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tribune7283' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Extraction"
      ],
      "metadata": {
        "id": "5lr-2tRGew6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset\n"
      ],
      "metadata": {
        "id": "KT-8oYYZ6lLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "2QffviWW5ZVX",
        "outputId": "360ec033-0a3f-48fa-d020-3048017b0d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File read successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                note\n",
              "0  Patient: John Smith, 58-year-old male\\nMedical...\n",
              "1  Patient: Linda Green, 45-year-old female\\nMedi...\n",
              "2  Patient: Michael Brown, 62-year-old male\\nMedi...\n",
              "3  Patient: Sarah Johnson, 50-year-old female\\nMe...\n",
              "4  Patient: Carlos Ramirez, 55-year-old male\\nMed..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccaad874-c333-473c-b9ed-16ae47f1ab53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Patient: John Smith, 58-year-old male\\nMedical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Patient: Linda Green, 45-year-old female\\nMedi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Patient: Michael Brown, 62-year-old male\\nMedi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Patient: Sarah Johnson, 50-year-old female\\nMe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Patient: Carlos Ramirez, 55-year-old male\\nMed...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccaad874-c333-473c-b9ed-16ae47f1ab53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ccaad874-c333-473c-b9ed-16ae47f1ab53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ccaad874-c333-473c-b9ed-16ae47f1ab53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f0133228-96e9-4575-bcde-e6ccff3d95ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0133228-96e9-4575-bcde-e6ccff3d95ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f0133228-96e9-4575-bcde-e6ccff3d95ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"An error occurred: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Patient: Linda Green, 45-year-old female\\nMedical Record #: 5678\\nChief Complaint: Persistent headaches and tingling in left foot.\\n\\nPast medical history includes Type 2 Diabetes, diagnosed three years ago. Current medications: Metformin 500 mg BID, Atorvastatin 10 mg daily. Last recorded A1C was 7.9%. Reports occasional insomnia, which she attributes to stress at her job as a florist. \\nShe mentioned her laptop battery died right before the telehealth visit, which caused a delay in connection. Reports that she recently started a home yoga routine recommended by her sister.\\n\\nPlan: Continue current medication regimen, order routine labs for lipids and A1C. Advise patient to monitor glucose levels more frequently if headaches persist.\",\n          \"Patient: Carlos Ramirez, 55-year-old male\\nMedical Record #: 2211\\nPresenting with ongoing fatigue and left knee pain. The knee issue may be orthopedic in nature due to a past sports injury.\\n\\nKnown history of Type 2 Diabetes, on Metformin 500 mg BID and Jardiance 10 mg daily. Last known A1C was 9.2%. He complains about his neighbor\\u2019s noisy parrot, which has disrupted his sleep. Currently also on Losartan 50 mg daily for hypertension. \\nNurse notes that the patient declined the flu shot, stating personal preference.\\n\\nAssessment & Plan: Increase Jardiance dosage if next labs still indicate poor glucose control. Recommend an orthopedic consult for knee pain. Counsel patient on sleep hygiene.\",\n          \"Patient: Michael Brown, 62-year-old male\\nMedical Record #: 9102\\nFollow-up for hypertension and Type 2 Diabetes. Patient arrived wearing a cast on his right arm (unrelated to current condition; he slipped on ice last week).\\n\\nVital signs: BP 150/95, pulse 78, temp 98.6\\u00b0F. On Metformin 1000 mg daily, Lisinopril 20 mg daily. Last known A1C was 8.1%. He also takes a multivitamin but couldn\\u2019t recall the brand. \\nHe mentioned watching the hospital cafeteria menu \\u201cgo digital\\u201d recently, which distracted him from asking the nurse some questions.\\n\\nNext step: Increase Lisinopril dose if BP remains elevated. Schedule blood tests to check renal function. Advise patient to keep arm elevated and follow up with orthopedics.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your XLSX file in Google Drive\n",
        "file_path = '/content/tribune7283/synthetic_clinical_notes.xlsx'\n",
        "\n",
        "# Read the XLSX file into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_excel(file_path)\n",
        "    print(\"File read successfully!\")\n",
        "    # Display the first 5 rows of the DataFrame\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file was not found at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RegEx Based Extraction"
      ],
      "metadata": {
        "id": "wL3c7hB9KtTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def extract_patient_info(note):\n",
        "    \"\"\"Extracts patient information using regex.\"\"\"\n",
        "    # Updated regex to capture first and last names separately\n",
        "    name_match = re.search(r\"Patient: (.*?)\\s(.*?)[,\\n]\", note)\n",
        "    age_match = re.search(r\"(\\d+)-year-old\", note)\n",
        "    gender_match = re.search(r\"-old (male|female)\", note)\n",
        "    mrn_match = re.search(r\"Medical Record #: (\\d+)\", note)\n",
        "\n",
        "    given_name = name_match.group(1).strip() if name_match else None\n",
        "    family_name = name_match.group(2).strip() if name_match else None\n",
        "    age = int(age_match.group(1)) if age_match else None\n",
        "    gender = gender_match.group(1) if gender_match else None\n",
        "    mrn = mrn_match.group(1) if mrn_match else None\n",
        "\n",
        "    return given_name, family_name, age, gender, mrn\n",
        "\n",
        "# Apply the function to the 'note' column and create new columns\n",
        "df[['given_name', 'family_name', 'age', 'gender', 'mrn']] = df['note'].apply(lambda x: pd.Series(extract_patient_info(x)))\n",
        "\n",
        "# Display the updated DataFrame with the new columns\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "Lrmv3wIm6aMw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1d5c650c-73cf-4ea7-edb5-4ddbc699d8ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                note given_name family_name  \\\n",
              "0  Patient: John Smith, 58-year-old male\\nMedical...       John       Smith   \n",
              "1  Patient: Linda Green, 45-year-old female\\nMedi...      Linda       Green   \n",
              "2  Patient: Michael Brown, 62-year-old male\\nMedi...    Michael       Brown   \n",
              "3  Patient: Sarah Johnson, 50-year-old female\\nMe...      Sarah     Johnson   \n",
              "4  Patient: Carlos Ramirez, 55-year-old male\\nMed...     Carlos     Ramirez   \n",
              "\n",
              "   age  gender   mrn  \n",
              "0   58    male  1234  \n",
              "1   45  female  5678  \n",
              "2   62    male  9102  \n",
              "3   50  female  3344  \n",
              "4   55    male  2211  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f22f2102-855d-4bd3-a99b-0f1756d70471\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>note</th>\n",
              "      <th>given_name</th>\n",
              "      <th>family_name</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>mrn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Patient: John Smith, 58-year-old male\\nMedical...</td>\n",
              "      <td>John</td>\n",
              "      <td>Smith</td>\n",
              "      <td>58</td>\n",
              "      <td>male</td>\n",
              "      <td>1234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Patient: Linda Green, 45-year-old female\\nMedi...</td>\n",
              "      <td>Linda</td>\n",
              "      <td>Green</td>\n",
              "      <td>45</td>\n",
              "      <td>female</td>\n",
              "      <td>5678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Patient: Michael Brown, 62-year-old male\\nMedi...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>Brown</td>\n",
              "      <td>62</td>\n",
              "      <td>male</td>\n",
              "      <td>9102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Patient: Sarah Johnson, 50-year-old female\\nMe...</td>\n",
              "      <td>Sarah</td>\n",
              "      <td>Johnson</td>\n",
              "      <td>50</td>\n",
              "      <td>female</td>\n",
              "      <td>3344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Patient: Carlos Ramirez, 55-year-old male\\nMed...</td>\n",
              "      <td>Carlos</td>\n",
              "      <td>Ramirez</td>\n",
              "      <td>55</td>\n",
              "      <td>male</td>\n",
              "      <td>2211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f22f2102-855d-4bd3-a99b-0f1756d70471')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f22f2102-855d-4bd3-a99b-0f1756d70471 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f22f2102-855d-4bd3-a99b-0f1756d70471');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f2ea1cef-3832-4fdc-af12-67880f173791\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2ea1cef-3832-4fdc-af12-67880f173791')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f2ea1cef-3832-4fdc-af12-67880f173791 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Patient: Linda Green, 45-year-old female\\nMedical Record #: 5678\\nChief Complaint: Persistent headaches and tingling in left foot.\\n\\nPast medical history includes Type 2 Diabetes, diagnosed three years ago. Current medications: Metformin 500 mg BID, Atorvastatin 10 mg daily. Last recorded A1C was 7.9%. Reports occasional insomnia, which she attributes to stress at her job as a florist. \\nShe mentioned her laptop battery died right before the telehealth visit, which caused a delay in connection. Reports that she recently started a home yoga routine recommended by her sister.\\n\\nPlan: Continue current medication regimen, order routine labs for lipids and A1C. Advise patient to monitor glucose levels more frequently if headaches persist.\",\n          \"Patient: Carlos Ramirez, 55-year-old male\\nMedical Record #: 2211\\nPresenting with ongoing fatigue and left knee pain. The knee issue may be orthopedic in nature due to a past sports injury.\\n\\nKnown history of Type 2 Diabetes, on Metformin 500 mg BID and Jardiance 10 mg daily. Last known A1C was 9.2%. He complains about his neighbor\\u2019s noisy parrot, which has disrupted his sleep. Currently also on Losartan 50 mg daily for hypertension. \\nNurse notes that the patient declined the flu shot, stating personal preference.\\n\\nAssessment & Plan: Increase Jardiance dosage if next labs still indicate poor glucose control. Recommend an orthopedic consult for knee pain. Counsel patient on sleep hygiene.\",\n          \"Patient: Michael Brown, 62-year-old male\\nMedical Record #: 9102\\nFollow-up for hypertension and Type 2 Diabetes. Patient arrived wearing a cast on his right arm (unrelated to current condition; he slipped on ice last week).\\n\\nVital signs: BP 150/95, pulse 78, temp 98.6\\u00b0F. On Metformin 1000 mg daily, Lisinopril 20 mg daily. Last known A1C was 8.1%. He also takes a multivitamin but couldn\\u2019t recall the brand. \\nHe mentioned watching the hospital cafeteria menu \\u201cgo digital\\u201d recently, which distracted him from asking the nurse some questions.\\n\\nNext step: Increase Lisinopril dose if BP remains elevated. Schedule blood tests to check renal function. Advise patient to keep arm elevated and follow up with orthopedics.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Linda\",\n          \"Carlos\",\n          \"Michael\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Green\",\n          \"Ramirez\",\n          \"Brown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 45,\n        \"max\": 62,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          45,\n          55,\n          62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrn\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"5678\",\n          \"2211\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from typing import Union\n",
        "\n",
        "def validate_given_name(name: Union[str, None]) -> bool:\n",
        "    \"\"\"Validates the patient's given name.\"\"\"\n",
        "    return isinstance(name, str) and 1 <= len(name) <= 50 # Assuming a reasonable length for a given name\n",
        "\n",
        "def validate_family_name(name: Union[str, None]) -> bool:\n",
        "    \"\"\"Validates the patient's family name.\"\"\"\n",
        "    return isinstance(name, str) and 1 <= len(name) <= 50 # Assuming a reasonable length for a family name\n",
        "\n",
        "def validate_age(age: Union[int, None]) -> bool:\n",
        "    \"\"\"Validates the patient's age.\"\"\"\n",
        "    # Check if age is an integer and within a reasonable range\n",
        "    return isinstance(age, int) and 0 <= age <= 120\n",
        "\n",
        "def validate_gender(gender: Union[str, None]) -> bool:\n",
        "    \"\"\"Validates the patient's gender.\"\"\"\n",
        "    # Check if gender is a string and is 'male' or 'female' (case-insensitive)\n",
        "    return isinstance(gender, str) and gender.lower() in ['male', 'female']\n",
        "\n",
        "def validate_mrn(mrn: Union[str, None]) -> bool:\n",
        "    \"\"\"Validates the patient's medical record number (MRN).\"\"\"\n",
        "    # Check if mrn is a string and matches the 4-digit pattern\n",
        "    return isinstance(mrn, str) and bool(re.fullmatch(r'\\d{4}', str(mrn)))\n",
        "\n",
        "\n",
        "def validate_patient_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Adds validation flags to the DataFrame.\"\"\"\n",
        "    df['given_name_valid'] = df['given_name'].apply(validate_given_name)\n",
        "    df['family_name_valid'] = df['family_name'].apply(validate_family_name)\n",
        "    df['age_valid'] = df['age'].apply(validate_age)\n",
        "    df['gender_valid'] = df['gender'].apply(validate_gender)\n",
        "    df['mrn_valid'] = df['mrn'].apply(validate_mrn)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the validation function to the DataFrame\n",
        "df = validate_patient_data(df.copy())\n",
        "\n",
        "# Display the DataFrame with validation flags\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "iyDAhnSPSGDp",
        "outputId": "f84cc44d-f2f2-4fc9-d0ec-ce3280993be6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 note given_name family_name  \\\n",
              "0   Patient: John Smith, 58-year-old male\\nMedical...       John       Smith   \n",
              "1   Patient: Linda Green, 45-year-old female\\nMedi...      Linda       Green   \n",
              "2   Patient: Michael Brown, 62-year-old male\\nMedi...    Michael       Brown   \n",
              "3   Patient: Sarah Johnson, 50-year-old female\\nMe...      Sarah     Johnson   \n",
              "4   Patient: Carlos Ramirez, 55-year-old male\\nMed...     Carlos     Ramirez   \n",
              "5   Patient: Rebecca Lee, 29-year-old female\\nMedi...    Rebecca         Lee   \n",
              "6   Patient: Thomas Wilson, 67-year-old male\\nMedi...     Thomas      Wilson   \n",
              "7   Patient: Emily Dawson, 36-year-old female\\nMed...      Emily      Dawson   \n",
              "8   Patient: Robert Kim, 48-year-old male\\nMedical...     Robert         Kim   \n",
              "9   Patient: Diane Carter, 60-year-old female\\nMed...      Diane      Carter   \n",
              "10  Patient: Lisa Chang, 72-year-old female\\nMedic...       Lisa       Chang   \n",
              "11  Patient: George Patterson, 55-year-old male\\nM...     George   Patterson   \n",
              "12  Patient: Maria Ortega, 63-year-old female\\nMed...      Maria      Ortega   \n",
              "13  Patient: Anthony Reynolds, 48-year-old male\\nM...    Anthony    Reynolds   \n",
              "14  Patient: Priya Kapoor, 34-year-old female\\nMed...      Priya      Kapoor   \n",
              "15  Patient: James Henderson, 59-year-old male\\nMe...      James   Henderson   \n",
              "16  Patient: Anna Li, 27-year-old female\\nMedical ...       Anna          Li   \n",
              "17  Patient: Kevin Wright, 66-year-old male\\nMedic...      Kevin      Wright   \n",
              "18  Patient: Olivia Baker, 43-year-old female\\nMed...     Olivia       Baker   \n",
              "19  Patient: David Kim, 70-year-old male\\nMedical ...      David         Kim   \n",
              "\n",
              "    age  gender   mrn  given_name_valid  family_name_valid  age_valid  \\\n",
              "0    58    male  1234              True               True       True   \n",
              "1    45  female  5678              True               True       True   \n",
              "2    62    male  9102              True               True       True   \n",
              "3    50  female  3344              True               True       True   \n",
              "4    55    male  2211              True               True       True   \n",
              "5    29  female  7788              True               True       True   \n",
              "6    67    male  9890              True               True       True   \n",
              "7    36  female  5566              True               True       True   \n",
              "8    48    male  3030              True               True       True   \n",
              "9    60  female  1212              True               True       True   \n",
              "10   72  female  4545              True               True       True   \n",
              "11   55    male  7676              True               True       True   \n",
              "12   63  female  3022              True               True       True   \n",
              "13   48    male  8833              True               True       True   \n",
              "14   34  female  1122              True               True       True   \n",
              "15   59    male  3339              True               True       True   \n",
              "16   27  female  5050              True               True       True   \n",
              "17   66    male  9292              True               True       True   \n",
              "18   43  female  7070              True               True       True   \n",
              "19   70    male  6262              True               True       True   \n",
              "\n",
              "    gender_valid  mrn_valid  \n",
              "0           True       True  \n",
              "1           True       True  \n",
              "2           True       True  \n",
              "3           True       True  \n",
              "4           True       True  \n",
              "5           True       True  \n",
              "6           True       True  \n",
              "7           True       True  \n",
              "8           True       True  \n",
              "9           True       True  \n",
              "10          True       True  \n",
              "11          True       True  \n",
              "12          True       True  \n",
              "13          True       True  \n",
              "14          True       True  \n",
              "15          True       True  \n",
              "16          True       True  \n",
              "17          True       True  \n",
              "18          True       True  \n",
              "19          True       True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-742c7ee6-3928-4a65-869f-060282e44528\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>note</th>\n",
              "      <th>given_name</th>\n",
              "      <th>family_name</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>mrn</th>\n",
              "      <th>given_name_valid</th>\n",
              "      <th>family_name_valid</th>\n",
              "      <th>age_valid</th>\n",
              "      <th>gender_valid</th>\n",
              "      <th>mrn_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Patient: John Smith, 58-year-old male\\nMedical...</td>\n",
              "      <td>John</td>\n",
              "      <td>Smith</td>\n",
              "      <td>58</td>\n",
              "      <td>male</td>\n",
              "      <td>1234</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Patient: Linda Green, 45-year-old female\\nMedi...</td>\n",
              "      <td>Linda</td>\n",
              "      <td>Green</td>\n",
              "      <td>45</td>\n",
              "      <td>female</td>\n",
              "      <td>5678</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Patient: Michael Brown, 62-year-old male\\nMedi...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>Brown</td>\n",
              "      <td>62</td>\n",
              "      <td>male</td>\n",
              "      <td>9102</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Patient: Sarah Johnson, 50-year-old female\\nMe...</td>\n",
              "      <td>Sarah</td>\n",
              "      <td>Johnson</td>\n",
              "      <td>50</td>\n",
              "      <td>female</td>\n",
              "      <td>3344</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Patient: Carlos Ramirez, 55-year-old male\\nMed...</td>\n",
              "      <td>Carlos</td>\n",
              "      <td>Ramirez</td>\n",
              "      <td>55</td>\n",
              "      <td>male</td>\n",
              "      <td>2211</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Patient: Rebecca Lee, 29-year-old female\\nMedi...</td>\n",
              "      <td>Rebecca</td>\n",
              "      <td>Lee</td>\n",
              "      <td>29</td>\n",
              "      <td>female</td>\n",
              "      <td>7788</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Patient: Thomas Wilson, 67-year-old male\\nMedi...</td>\n",
              "      <td>Thomas</td>\n",
              "      <td>Wilson</td>\n",
              "      <td>67</td>\n",
              "      <td>male</td>\n",
              "      <td>9890</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Patient: Emily Dawson, 36-year-old female\\nMed...</td>\n",
              "      <td>Emily</td>\n",
              "      <td>Dawson</td>\n",
              "      <td>36</td>\n",
              "      <td>female</td>\n",
              "      <td>5566</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Patient: Robert Kim, 48-year-old male\\nMedical...</td>\n",
              "      <td>Robert</td>\n",
              "      <td>Kim</td>\n",
              "      <td>48</td>\n",
              "      <td>male</td>\n",
              "      <td>3030</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Patient: Diane Carter, 60-year-old female\\nMed...</td>\n",
              "      <td>Diane</td>\n",
              "      <td>Carter</td>\n",
              "      <td>60</td>\n",
              "      <td>female</td>\n",
              "      <td>1212</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Patient: Lisa Chang, 72-year-old female\\nMedic...</td>\n",
              "      <td>Lisa</td>\n",
              "      <td>Chang</td>\n",
              "      <td>72</td>\n",
              "      <td>female</td>\n",
              "      <td>4545</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Patient: George Patterson, 55-year-old male\\nM...</td>\n",
              "      <td>George</td>\n",
              "      <td>Patterson</td>\n",
              "      <td>55</td>\n",
              "      <td>male</td>\n",
              "      <td>7676</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Patient: Maria Ortega, 63-year-old female\\nMed...</td>\n",
              "      <td>Maria</td>\n",
              "      <td>Ortega</td>\n",
              "      <td>63</td>\n",
              "      <td>female</td>\n",
              "      <td>3022</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Patient: Anthony Reynolds, 48-year-old male\\nM...</td>\n",
              "      <td>Anthony</td>\n",
              "      <td>Reynolds</td>\n",
              "      <td>48</td>\n",
              "      <td>male</td>\n",
              "      <td>8833</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Patient: Priya Kapoor, 34-year-old female\\nMed...</td>\n",
              "      <td>Priya</td>\n",
              "      <td>Kapoor</td>\n",
              "      <td>34</td>\n",
              "      <td>female</td>\n",
              "      <td>1122</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Patient: James Henderson, 59-year-old male\\nMe...</td>\n",
              "      <td>James</td>\n",
              "      <td>Henderson</td>\n",
              "      <td>59</td>\n",
              "      <td>male</td>\n",
              "      <td>3339</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Patient: Anna Li, 27-year-old female\\nMedical ...</td>\n",
              "      <td>Anna</td>\n",
              "      <td>Li</td>\n",
              "      <td>27</td>\n",
              "      <td>female</td>\n",
              "      <td>5050</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Patient: Kevin Wright, 66-year-old male\\nMedic...</td>\n",
              "      <td>Kevin</td>\n",
              "      <td>Wright</td>\n",
              "      <td>66</td>\n",
              "      <td>male</td>\n",
              "      <td>9292</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Patient: Olivia Baker, 43-year-old female\\nMed...</td>\n",
              "      <td>Olivia</td>\n",
              "      <td>Baker</td>\n",
              "      <td>43</td>\n",
              "      <td>female</td>\n",
              "      <td>7070</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Patient: David Kim, 70-year-old male\\nMedical ...</td>\n",
              "      <td>David</td>\n",
              "      <td>Kim</td>\n",
              "      <td>70</td>\n",
              "      <td>male</td>\n",
              "      <td>6262</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742c7ee6-3928-4a65-869f-060282e44528')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-742c7ee6-3928-4a65-869f-060282e44528 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-742c7ee6-3928-4a65-869f-060282e44528');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fc4f84e5-d7f7-4abd-95cb-f74b300c0f92\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc4f84e5-d7f7-4abd-95cb-f74b300c0f92')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fc4f84e5-d7f7-4abd-95cb-f74b300c0f92 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_95c6c07d-02ef-489f-9125-613a99061aa3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_95c6c07d-02ef-489f-9125-613a99061aa3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Patient: John Smith, 58-year-old male\\nMedical Record #: 1234\\nArrived for a follow-up appointment complaining of ongoing fatigue and occasional blurred vision. Denies chest pain.\\n\\nKnown history of Type 2 Diabetes (T2D), currently on Metformin 500 mg BID and occasional insulin injections. Previous lab work indicated an elevated A1C of 8.7%. The patient also mentioned that his cat, Fluffy, seems lethargic lately. The overhead fluorescent lights in the waiting area were flickering, making it difficult to read the nurse's quick notes.\\n\\nHe reports mild numbness in his feet, suggesting early peripheral neuropathy. Other comorbidity includes hypertension, managed with Lisinopril 20 mg daily. Nurse Linda noted that he had tested negative for COVID-19 last month.\\n\\nNext step: schedule a fasting glucose test in two weeks to reassess. Consider adjusting insulin dosage if glucose remains high. Also, the patient could not recall if he still smokes occasionally. Overall plan is to reinforce medication adherence and review dietary habits at the next visit.\",\n          \"Patient: Kevin Wright, 66-year-old male\\nMedical Record #: 9292\\nFollow-up for Type 2 Diabetes and chronic back pain. States the pain worsens when he sits in his recliner too long.\\n\\nCurrent meds: Metformin 500 mg TID, Ibuprofen PRN for back pain, and Lisinopril 10 mg daily for mild hypertension. Last A1C: 8.9%. He\\u2019s annoyed that the pharmacy recently changed his pill bottle labels, making them harder to read. \\nComplains of slight dizziness upon standing, possibly orthostatic. He also mentions he\\u2019s been skipping breakfast, which might contribute to blood sugar swings.\\n\\nAssessment & Plan: Evaluate orthostatic hypotension. Increase dietary supervision, possibly add short-acting insulin if glycemic control remains inadequate. Suggest physical therapy referral for back pain.\",\n          \"Patient: James Henderson, 59-year-old male\\nMedical Record #: 3339\\nRoutine check-up for Type 2 Diabetes and hyperlipidemia. Patient states he has minimal exercise since winter started.\\n\\nMedications: Metformin 1000 mg BID, Rosuvastatin 10 mg daily. Last A1C was 7.5%. He mentions a new hobby, amateur radio, which keeps him seated for prolonged periods. He forgot to wear his glasses today, making it hard to read the consent forms.\\nPlan: Encourage more physical activity, potentially indoors. Order new labs to monitor lipid profile and blood glucose control. Discuss possible addition of medication for better glycemic management if needed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"John\",\n          \"Kevin\",\n          \"James\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Smith\",\n          \"Lee\",\n          \"Patterson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 27,\n        \"max\": 72,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          58,\n          45,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrn\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"1234\",\n          \"9292\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name_valid\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_name_valid\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_valid\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender_valid\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrn_valid\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Based Extraction"
      ],
      "metadata": {
        "id": "LCjLjy-GIwuy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0477d2c0"
      },
      "source": [
        "### Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0895fbe0",
        "outputId": "1450e146-5622-4414-ba44-401fee7aafeb"
      },
      "source": [
        "%pip install semantic-kernel openai transformers semantic-kernel[anthropic]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semantic-kernel\n",
            "  Downloading semantic_kernel-1.35.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.99.8)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Collecting azure-ai-projects>=1.0.0b12 (from semantic-kernel)\n",
            "  Downloading azure_ai_projects-1.1.0b2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting azure-ai-agents>=1.1.0b4 (from semantic-kernel)\n",
            "  Downloading azure_ai_agents-1.2.0b2-py3-none-any.whl.metadata (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp~=3.8 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (3.12.15)\n",
            "Collecting cloudevents~=1.0 (from semantic-kernel)\n",
            "  Downloading cloudevents-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (2.11.7)\n",
            "Collecting pydantic-settings~=2.0 (from semantic-kernel)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: defusedxml~=0.7 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (0.7.1)\n",
            "Collecting azure-identity>=1.13 (from semantic-kernel)\n",
            "  Downloading azure_identity-1.24.0-py3-none-any.whl.metadata (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (2.0.2)\n",
            "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
            "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: websockets<16,>=13 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (15.0.1)\n",
            "Collecting aiortc>=1.9.0 (from semantic-kernel)\n",
            "  Downloading aiortc-1.13.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting opentelemetry-api~=1.24 (from semantic-kernel)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting prance<25.4.9,>=23.6.21 (from semantic-kernel)\n",
            "  Downloading prance-25.4.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pybars4~=0.9 (from semantic-kernel)\n",
            "  Downloading pybars4-0.9.13.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2~=3.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (3.1.6)\n",
            "Requirement already satisfied: nest-asyncio~=1.6 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (1.16.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (5.29.5)\n",
            "Requirement already satisfied: typing-extensions>=4.13 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (4.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Collecting anthropic~=0.32 (from semantic-kernel[anthropic])\n",
            "  Downloading anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (1.20.1)\n",
            "Collecting aioice<1.0.0,>=0.10.1 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading aioice-0.10.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting av<15.0.0,>=14.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
            "Collecting cryptography>=44.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-crc32c>=1.1 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
            "Collecting pyee>=13.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pylibsrtp>=0.10.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading pylibsrtp-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting pyopenssl>=25.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading pyopenssl-25.1.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-agents>=1.1.0b4->semantic-kernel)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure-ai-agents>=1.1.0b4->semantic-kernel)\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.15.0 (from azure-ai-projects>=1.0.0b12->semantic-kernel)\n",
            "  Downloading azure_storage_blob-12.26.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting msal>=1.30.0 (from azure-identity>=1.13->semantic-kernel)\n",
            "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity>=1.13->semantic-kernel)\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting deprecation<3.0,>=2.0 (from cloudevents~=1.0->semantic-kernel)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.0)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.7.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting werkzeug<3.1.2 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.7.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk~=1.24->semantic-kernel)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: chardet>=5.2 in /usr/local/lib/python3.11/dist-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (5.2.0)\n",
            "Collecting ruamel.yaml>=0.18.10 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel)\n",
            "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings~=2.0->semantic-kernel)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Collecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-ai-agents>=1.1.0b4->semantic-kernel) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.27.0)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
            "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading lazy_object_proxy-1.11.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading semantic_kernel-1.35.3-py3-none-any.whl (882 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m882.4/882.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiortc-1.13.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.64.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_agents-1.2.0b2-py3-none-any.whl (204 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_projects-1.1.0b2-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.24.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.9/187.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudevents-1.12.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prance-25.4.8.0-py3-none-any.whl (36 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioice-0.10.1-py3-none-any.whl (24 kB)\n",
            "Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.26.0-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
            "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading pylibsrtp-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyopenssl-25.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading lazy_object_proxy-1.11.0-py3-none-any.whl (16 kB)\n",
            "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Building wheels for collected packages: pybars4, PyMeta3\n",
            "  Building wheel for pybars4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14340 sha256=fc60bfd2f50d5e2839ea0bb4cb9811c9482def2a4307dc95f39fd4e7b24d3756\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/91/9b/2590c830475e613f1996fe9ce7876d5d31c346fb73a48838ad\n",
            "  Building wheel for PyMeta3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyMeta3: filename=PyMeta3-0.5.1-py3-none-any.whl size=16449 sha256=9bc38f1ece49596f861d47e4ffb8d6639a284c9493ee9361fd038bd42b7cd27d\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/18/5a/5a3a19ff18c8118a8dd11204dcde08349c2bbbdd77ac45b6a7\n",
            "Successfully built pybars4 PyMeta3\n",
            "Installing collected packages: PyMeta3, parse, ifaddr, werkzeug, ruamel.yaml.clib, rfc3339-validator, python-dotenv, pyee, pybars4, pathable, lazy-object-proxy, isodate, dnspython, deprecation, av, ruamel.yaml, pylibsrtp, opentelemetry-api, jsonschema-path, cryptography, cloudevents, azure-core, aioice, pyopenssl, pydantic-settings, prance, opentelemetry-semantic-conventions, azure-storage-blob, azure-ai-agents, anthropic, opentelemetry-sdk, openapi-schema-validator, msal, azure-ai-projects, aiortc, openapi-spec-validator, msal-extensions, openapi_core, azure-identity, semantic-kernel\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: pyopenssl\n",
            "    Found existing installation: pyOpenSSL 24.2.1\n",
            "    Uninstalling pyOpenSSL-24.2.1:\n",
            "      Successfully uninstalled pyOpenSSL-24.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 45.0.6 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMeta3-0.5.1 aioice-0.10.1 aiortc-1.13.0 anthropic-0.64.0 av-14.4.0 azure-ai-agents-1.2.0b2 azure-ai-projects-1.1.0b2 azure-core-1.35.0 azure-identity-1.24.0 azure-storage-blob-12.26.0 cloudevents-1.12.0 cryptography-45.0.6 deprecation-2.1.0 dnspython-2.7.0 ifaddr-0.2.0 isodate-0.7.2 jsonschema-path-0.3.4 lazy-object-proxy-1.11.0 msal-1.33.0 msal-extensions-1.3.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 openapi_core-0.19.5 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 parse-1.20.2 pathable-0.4.4 prance-25.4.8.0 pybars4-0.9.13 pydantic-settings-2.10.1 pyee-13.0.0 pylibsrtp-0.12.0 pyopenssl-25.1.0 python-dotenv-1.1.1 rfc3339-validator-0.1.4 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semantic-kernel-1.35.3 werkzeug-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c26d746"
      },
      "source": [
        "### Configure semantic kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6152bb0",
        "outputId": "6d8d248b-f9cd-48bf-883d-fa8012d8147e"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata # Import userdata to access Colab secrets\n",
        "\n",
        "import semantic_kernel as sk\n",
        "\n",
        "# Use the import path and class provided by the user\n",
        "try:\n",
        "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
        "    print(\"Successfully imported OpenAIChatCompletion from semantic_kernel.connectors.ai.open_ai\")\n",
        "    OpenAI_Connector = OpenAIChatCompletion # Alias for easier use\n",
        "except ImportError as e:\n",
        "    print(f\"Import Error: {e}\")\n",
        "    print(\"Could not import OpenAIChatCompletion from semantic_kernel.connectors.ai.open_ai.\")\n",
        "    print(\"Please ensure your semantic-kernel version is compatible with this import path.\")\n",
        "    OpenAI_Connector = None # Set to None if import fails\n",
        "\n",
        "\n",
        "# 2. Initialize a Semantic Kernel instance.\n",
        "# Check if kernel is already initialized to avoid re-initialization if this cell is run after a cell that initializes it.\n",
        "if 'kernel' not in globals() or not isinstance(kernel, sk.Kernel):\n",
        "    kernel = sk.Kernel()\n",
        "    print(\"Semantic Kernel initialized.\")\n",
        "else:\n",
        "    print(\"Semantic Kernel already initialized.\")\n",
        "\n",
        "\n",
        "# 3. Get the OpenAI API key from Colab secrets using userdata.get().\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# 4. Add the GPT-4o model to the kernel's services.\n",
        "gpt4o_model_name = \"gpt-4o-2024-08-06\" # Setting the model name explicitly to gpt-4o\n",
        "gpt_service_id = \"gpt_service\" # Renaming service ID for clarity\n",
        "\n",
        "if OpenAI_Connector and openai_api_key:\n",
        "    try:\n",
        "        # Use the provided template structure for adding the service\n",
        "        #chat_completion_service = OpenAI_Connector(\n",
        "        chat_completion_service = OpenAI_Connector(\n",
        "            ai_model_id=gpt4o_model_name,\n",
        "            api_key=openai_api_key,\n",
        "            service_id=gpt_service_id,\n",
        "        )\n",
        "        # Add the chat service to the kernel (assuming add_chat_service method exists in v1.x)\n",
        "        kernel.add_service(chat_completion_service)\n",
        "\n",
        "        print(f\"'{gpt4o_model_name}' (service_id: {gpt_service_id}) added to the kernel as a chat service.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding OpenAI service '{gpt4o_model_name}': {e}\")\n",
        "        print(\"OpenAI service not added. Please check your OPENAI_API_KEY in Colab secrets and the semantic-kernel version compatibility.\")\n",
        "else:\n",
        "    if not OpenAI_Connector:\n",
        "        print(\"OpenAI connector class not available due to import failure.\")\n",
        "    else:\n",
        "        print(\"OpenAI API key not found in Colab secrets. OpenAI service not added.\")\n",
        "\n",
        "print(\"\\nOpenAI service addition attempt complete.\")\n",
        "# print(\"Kernel services:\", kernel.get_service_ids()) # get_service_ids might cause AttributeError\n",
        "print(\"Check kernel services manually if needed based on your SK version.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported OpenAIChatCompletion from semantic_kernel.connectors.ai.open_ai\n",
            "Semantic Kernel already initialized.\n",
            "'gpt-4o-2024-08-06' (service_id: gpt_service) added to the kernel as a chat service.\n",
            "\n",
            "OpenAI service addition attempt complete.\n",
            "Check kernel services manually if needed based on your SK version.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d34cfc26"
      },
      "source": [
        "### Create semantic functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df108e0a",
        "outputId": "dfe556f9-6c76-49c8-8b3f-3f5fdf380ce8"
      },
      "source": [
        "import semantic_kernel as sk\n",
        "import asyncio # Import asyncio for running async functions\n",
        "from typing import Dict, Any\n",
        "from google.colab import drive # Import drive to mount Google Drive\n",
        "from semantic_kernel.contents.chat_history import ChatHistory # Import ChatHistory\n",
        "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings # Import execution settings class\n",
        "\n",
        "# Define execution settings for OpenAI chat completion\n",
        "execution_settings = OpenAIChatPromptExecutionSettings()\n",
        "\n",
        "\n",
        "# Specify the path to the prompt file in Google Drive\n",
        "prompt_file_path = '/content/tribune7283/json_extraction_prompt_v2.txt'\n",
        "\n",
        "# Read the prompt from the file\n",
        "try:\n",
        "    with open(prompt_file_path, 'r') as f:\n",
        "        json_extraction_prompt = f.read()\n",
        "    print(f\"Prompt read successfully from {prompt_file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The prompt file was not found at {prompt_file_path}\")\n",
        "    json_extraction_prompt = None # Set prompt to None if file not loaded\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the prompt file: {e}\")\n",
        "    json_extraction_prompt = None # Set prompt to None if error occurs\n",
        "\n",
        "\n",
        "# Define the asynchronous function for GPT-4o processing using the correct v1.x invocation pattern\n",
        "async def process_note_gpt4o(note: str) -> str:\n",
        "    \"\"\"Processes the medical note using the GPT-4o model via Semantic Kernel.\"\"\"\n",
        "    print(\"Processing note with GPT-4o...\")\n",
        "    if json_extraction_prompt is None:\n",
        "        return \"Error: Prompt file not loaded.\"\n",
        "\n",
        "    try:\n",
        "        # Get the text generation service by ID (Correct v1.x pattern)\n",
        "        gpt_service = kernel.get_service(gpt_service_id)\n",
        "        if gpt_service:\n",
        "            # Create a ChatHistory object and add messages\n",
        "            chat_history = ChatHistory()\n",
        "            chat_history.add_system_message(\"You are a helpful medical assistant that extracts information.\")\n",
        "            chat_history.add_user_message(f\"{json_extraction_prompt}\\n\\nMedical Note:\\n{note}\\n\\nExtracted Information:\")\n",
        "\n",
        "\n",
        "            # Check if the service has the chat_completion method (typical for OpenAI chat services)\n",
        "            if hasattr(gpt_service, 'get_chat_message_content'):\n",
        "                 # Invoke the chat completion method using execution_settings\n",
        "                chat_completion = await gpt_service.get_chat_message_content(chat_history, settings=execution_settings)\n",
        "                gpt_output = chat_completion\n",
        "            elif hasattr(gpt_service, 'generate_text'):\n",
        "                 # Fallback to generate_text if it exists (less likely for gpt-4o)\n",
        "                 print(\"Warning: Using generate_text for GPT-4o service, but it might be a chat model.\")\n",
        "                 gpt_output = await gpt_service.generate_text(chat_history.messages_to_prompt()) # Convert ChatHistory to prompt string\n",
        "            else:\n",
        "                 raise AttributeError(f\"Service '{gpt_service_id}' does not have expected generation method.\")\n",
        "\n",
        "\n",
        "            print(\"GPT-4o processing successful.\")\n",
        "            return str(gpt_output)\n",
        "        else:\n",
        "            return f\"Error processing with GPT-4o: Service '{gpt_service_id}' not found in kernel.\"\n",
        "    except AttributeError as e:\n",
        "        print(f\"AttributeError processing with GPT-4o: {e}\")\n",
        "        return f\"AttributeError processing with GPT-4o: {e}\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during GPT-4o processing: {e}\")\n",
        "        return f\"An unexpected error occurred during GPT-4o processing: {e}\"\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt read successfully from /content/tribune7283/json_extraction_prompt_v2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3ab4b2",
        "outputId": "ffbb0939-fa90-40a5-a65f-463d584ed070"
      },
      "source": [
        "import asyncio # Ensure asyncio is imported for running async functions\n",
        "import json # Import json for handling JSON data\n",
        "import os # Import os for path joining\n",
        "import pandas as pd # Ensure pandas is imported\n",
        "\n",
        "\n",
        "async def process_medical_notes(df: pd.DataFrame, sample_size: int = 0, seed: int = 42):\n",
        "    \"\"\"\n",
        "    Processes medical notes from a DataFrame using GPT-4o via Semantic Kernel.\n",
        "\n",
        "    Args:\n",
        "        df: The input DataFrame containing medical notes in a 'note' column.\n",
        "        sample_size: The number of notes to sample. If 0 or None, process the full dataset.\n",
        "        seed: The random seed for reproducible sampling.\n",
        "    \"\"\"\n",
        "    # --- Select notes for processing ---\n",
        "    if sample_size and sample_size > 0:\n",
        "        print(f\"Processing a reproducible sample of {sample_size} notes (seed: {seed}).\")\n",
        "        # Ensure sample size does not exceed the number of notes available\n",
        "        num_notes = len(df['note'])\n",
        "        actual_sample_size = min(sample_size, num_notes)\n",
        "        if actual_sample_size < sample_size:\n",
        "            print(f\"Warning: Requested sample size ({sample_size}) is larger than available notes ({num_notes}). Processing all available notes.\")\n",
        "            notes_to_process = df['note'].tolist()\n",
        "        else:\n",
        "             # Select a reproducible sample of medical notes from the 'note' column\n",
        "            notes_to_process = df['note'].sample(n=actual_sample_size, random_state=seed).tolist()\n",
        "    else:\n",
        "        print(\"Processing the full dataset.\")\n",
        "        # Use the entire 'note' column\n",
        "        notes_to_process = df['note'].tolist()\n",
        "\n",
        "\n",
        "    # Define a directory to save the outputs (optional, but good practice)\n",
        "    output_dir = \"extracted_outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Output directory '{output_dir}' created or already exists.\")\n",
        "\n",
        "    # Define the path for the single output JSON file\n",
        "    single_output_json_file = os.path.join(output_dir, \"all_extracted_gpt4o_outputs.json\")\n",
        "\n",
        "\n",
        "    # 2. Run the asynchronous processing function for the selected notes with GPT-4o only\n",
        "    results = []\n",
        "    successfully_parsed_json_outputs = [] # List to collect successfully parsed JSON objects\n",
        "    print(f\"\\n--- Running Semantic Kernel Processing on {len(notes_to_process)} Notes ---\")\n",
        "\n",
        "    async def process_list_of_notes(notes):\n",
        "        processed_count = 0\n",
        "        for i, note in enumerate(notes):\n",
        "            processed_count += 1\n",
        "            print(f\"\\n--- Processing Note {i+1}/{len(notes)} ---\")\n",
        "            gpt_output = await process_note_gpt4o(note)\n",
        "\n",
        "            results.append({\n",
        "                \"original_note\": note, # Store the full original note\n",
        "                \"gpt_output\": gpt_output, # Store the full GPT-4o output\n",
        "            })\n",
        "            print(f\"Finished processing Note {i+1}. Total processed: {processed_count}\")\n",
        "\n",
        "            # Attempt to parse the GPT-4o output as JSON and add to the collection list\n",
        "            full_gpt_output_str = gpt_output\n",
        "            try:\n",
        "                json_start = full_gpt_output_str.find('{')\n",
        "                json_end = full_gpt_output_str.rfind('}')\n",
        "                if json_start != -1 and json_end != -1 and json_end > json_start:\n",
        "                    json_string = full_gpt_output_str[json_start : json_end + 1]\n",
        "                    gpt_output_json = json.loads(json_string)\n",
        "                    successfully_parsed_json_outputs.append(gpt_output_json)\n",
        "                    print(f\"Successfully parsed JSON for Note {i+1}.\")\n",
        "                else:\n",
        "                     print(f\"Warning: Could not find a valid JSON object in GPT-4o output for Note {i+1}. Skipping JSON collection for this note.\")\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON from GPT-4o output for Note {i+1}: {e}. Skipping JSON collection for this note.\")\n",
        "            except Exception as e:\n",
        "                 print(f\"An unexpected error occurred during JSON parsing for Note {i+1}: {e}. Skipping JSON collection for this note.\")\n",
        "\n",
        "\n",
        "        return results\n",
        "\n",
        "    # Run the asynchronous note processing\n",
        "    processed_results = await process_list_of_notes(notes_to_process)\n",
        "\n",
        "\n",
        "    # 3. Display the outputs (optional, but good for monitoring)\n",
        "    print(\"\\n--- Semantic Kernel Processing Results Preview ---\")\n",
        "    for i, result_data in enumerate(processed_results):\n",
        "        if i >= 3: # Display preview for only the first few notes\n",
        "            break\n",
        "        print(f\"\\n--- Results for Note {i+1} ---\")\n",
        "        # Display full original note\n",
        "        full_original_note = result_data.get(\"original_note\", \"N/A\")\n",
        "        # Display full GPT-4o output (truncated for display)\n",
        "        full_gpt_output_str = result_data.get(\"gpt_output\", \"N/A\")\n",
        "\n",
        "\n",
        "        print(\"Original Note (first 100 chars):\", full_original_note[:100] + \"...\")\n",
        "        print(\"GPT-4o Output (first 500 chars):\", full_gpt_output_str[:500] + \"...\")\n",
        "\n",
        "\n",
        "    # 4. Save all successfully parsed JSON outputs to a single file\n",
        "    print(f\"\\n--- Saving All Parsed JSON Outputs to {single_output_json_file} ---\")\n",
        "    if successfully_parsed_json_outputs:\n",
        "        try:\n",
        "            with open(single_output_json_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(successfully_parsed_json_outputs, f, indent=4)\n",
        "            print(f\"Successfully saved {len(successfully_parsed_json_outputs)} parsed JSON objects to {single_output_json_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving the single JSON output file {single_output_json_file}: {e}\")\n",
        "    else:\n",
        "        print(\"No valid JSON outputs were successfully parsed to save.\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Processing and Saving Complete ---\")\n",
        "    return processed_results # Return the list of raw results for potential downstream use (like evaluation)\n",
        "\n",
        "\n",
        "# Example of how to call the function:\n",
        "# await process_medical_notes(df, sample_size=5, seed=123) # Process a sample of 5 notes\n",
        "# await process_medical_notes(df) # Process the full dataset (if sample_size is 0 or None)\n",
        "\n",
        "result_list = await process_medical_notes(df, sample_size=0, seed=42)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the full dataset.\n",
            "Output directory 'extracted_outputs' created or already exists.\n",
            "\n",
            "--- Running Semantic Kernel Processing on 20 Notes ---\n",
            "\n",
            "--- Processing Note 1/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 1. Total processed: 1\n",
            "Successfully parsed JSON for Note 1.\n",
            "\n",
            "--- Processing Note 2/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 2. Total processed: 2\n",
            "Successfully parsed JSON for Note 2.\n",
            "\n",
            "--- Processing Note 3/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 3. Total processed: 3\n",
            "Successfully parsed JSON for Note 3.\n",
            "\n",
            "--- Processing Note 4/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 4. Total processed: 4\n",
            "Successfully parsed JSON for Note 4.\n",
            "\n",
            "--- Processing Note 5/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 5. Total processed: 5\n",
            "Successfully parsed JSON for Note 5.\n",
            "\n",
            "--- Processing Note 6/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 6. Total processed: 6\n",
            "Successfully parsed JSON for Note 6.\n",
            "\n",
            "--- Processing Note 7/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 7. Total processed: 7\n",
            "Successfully parsed JSON for Note 7.\n",
            "\n",
            "--- Processing Note 8/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 8. Total processed: 8\n",
            "Successfully parsed JSON for Note 8.\n",
            "\n",
            "--- Processing Note 9/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 9. Total processed: 9\n",
            "Successfully parsed JSON for Note 9.\n",
            "\n",
            "--- Processing Note 10/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 10. Total processed: 10\n",
            "Successfully parsed JSON for Note 10.\n",
            "\n",
            "--- Processing Note 11/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 11. Total processed: 11\n",
            "Successfully parsed JSON for Note 11.\n",
            "\n",
            "--- Processing Note 12/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 12. Total processed: 12\n",
            "Successfully parsed JSON for Note 12.\n",
            "\n",
            "--- Processing Note 13/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 13. Total processed: 13\n",
            "Successfully parsed JSON for Note 13.\n",
            "\n",
            "--- Processing Note 14/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 14. Total processed: 14\n",
            "Successfully parsed JSON for Note 14.\n",
            "\n",
            "--- Processing Note 15/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 15. Total processed: 15\n",
            "Successfully parsed JSON for Note 15.\n",
            "\n",
            "--- Processing Note 16/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 16. Total processed: 16\n",
            "Successfully parsed JSON for Note 16.\n",
            "\n",
            "--- Processing Note 17/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 17. Total processed: 17\n",
            "Successfully parsed JSON for Note 17.\n",
            "\n",
            "--- Processing Note 18/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 18. Total processed: 18\n",
            "Successfully parsed JSON for Note 18.\n",
            "\n",
            "--- Processing Note 19/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 19. Total processed: 19\n",
            "Successfully parsed JSON for Note 19.\n",
            "\n",
            "--- Processing Note 20/20 ---\n",
            "Processing note with GPT-4o...\n",
            "GPT-4o processing successful.\n",
            "Finished processing Note 20. Total processed: 20\n",
            "Successfully parsed JSON for Note 20.\n",
            "\n",
            "--- Semantic Kernel Processing Results Preview ---\n",
            "\n",
            "--- Results for Note 1 ---\n",
            "Original Note (first 100 chars): Patient: John Smith, 58-year-old male\n",
            "Medical Record #: 1234\n",
            "Arrived for a follow-up appointment com...\n",
            "GPT-4o Output (first 500 chars): ```json\n",
            "{\n",
            "  \"record_metadata\": {\n",
            "    \"patient_name\": \"John Smith\",\n",
            "    \"medical_record_number\": \"1234\"\n",
            "  },\n",
            "  \"demographics\": {\n",
            "    \"age_years\": 58,\n",
            "    \"sex\": \"male\",\n",
            "    \"race_ethnicity\": null,\n",
            "    \"socioeconomic_class\": null\n",
            "  },\n",
            "  \"diagnoses\": [\n",
            "    {\n",
            "      \"condition\": {\n",
            "        \"snomed_code\": null,\n",
            "        \"snomed_term\": \"Type 2 diabetes mellitus\"\n",
            "      },\n",
            "      \"status\": \"active\",\n",
            "      \"status_evidence\": \"Known history of Type 2 Diabetes (T2D)\",\n",
            "      \"diagnosis_date\": null,\n",
            "      \"appro...\n",
            "\n",
            "--- Results for Note 2 ---\n",
            "Original Note (first 100 chars): Patient: Linda Green, 45-year-old female\n",
            "Medical Record #: 5678\n",
            "Chief Complaint: Persistent headache...\n",
            "GPT-4o Output (first 500 chars): ```json\n",
            "{\n",
            "  \"record_metadata\": {\n",
            "    \"patient_name\": \"Linda Green\",\n",
            "    \"medical_record_number\": \"5678\"\n",
            "  },\n",
            "  \"demographics\": {\n",
            "    \"age_years\": 45,\n",
            "    \"sex\": \"female\",\n",
            "    \"race_ethnicity\": null,\n",
            "    \"socioeconomic_class\": null\n",
            "  },\n",
            "  \"diagnoses\": [\n",
            "    {\n",
            "      \"condition\": {\n",
            "        \"snomed_code\": null,\n",
            "        \"snomed_term\": \"Type 2 diabetes mellitus\"\n",
            "      },\n",
            "      \"status\": \"active\",\n",
            "      \"status_evidence\": \"Past medical history includes Type 2 Diabetes, diagnosed three years ago\",\n",
            "     ...\n",
            "\n",
            "--- Results for Note 3 ---\n",
            "Original Note (first 100 chars): Patient: Michael Brown, 62-year-old male\n",
            "Medical Record #: 9102\n",
            "Follow-up for hypertension and Type ...\n",
            "GPT-4o Output (first 500 chars): ```json\n",
            "{\n",
            "  \"record_metadata\": {\n",
            "    \"patient_name\": \"Michael Brown\",\n",
            "    \"medical_record_number\": \"9102\"\n",
            "  },\n",
            "  \"demographics\": {\n",
            "    \"age_years\": 62,\n",
            "    \"sex\": \"male\",\n",
            "    \"race_ethnicity\": null,\n",
            "    \"socioeconomic_class\": null\n",
            "  },\n",
            "  \"diagnoses\": [\n",
            "    {\n",
            "      \"condition\": {\n",
            "        \"snomed_code\": null,\n",
            "        \"snomed_term\": \"Type 2 diabetes mellitus\"\n",
            "      },\n",
            "      \"status\": \"active\",\n",
            "      \"status_evidence\": \"Follow-up for Type 2 Diabetes\",\n",
            "      \"diagnosis_date\": null,\n",
            "      \"approx_diag...\n",
            "\n",
            "--- Saving All Parsed JSON Outputs to extracted_outputs/all_extracted_gpt4o_outputs.json ---\n",
            "Successfully saved 20 parsed JSON objects to extracted_outputs/all_extracted_gpt4o_outputs.json\n",
            "\n",
            "--- Processing and Saving Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata # Import userdata to access Colab secrets\n",
        "\n",
        "import semantic_kernel as sk\n",
        "\n",
        "from semantic_kernel.connectors.ai.anthropic import AnthropicChatCompletion\n",
        "print(\"Successfully imported AnthropicChatCompletion from semantic_kernel.connectors.ai.anthropic\")\n",
        "Anthropic_Connector = AnthropicChatCompletion # Alias for easier use\n",
        "\n",
        "\n",
        "if 'kernel' not in globals() or not isinstance(kernel, sk.Kernel):\n",
        "    print(\"Semantic Kernel not initialized. Please run the previous cell to initialize the kernel.\")\n",
        "\n",
        "\n",
        "# 3. Get the Anthropic API key from Colab secrets using userdata.get().\n",
        "anthropic_api_key = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "# 4. Add the Anthropic model to the kernel's services.\n",
        "anthropic_model_name = \"claude-opus-4-1-20250805\"\n",
        "anthropic_service_id = \"anthropic_service\"\n",
        "\n",
        "if Anthropic_Connector and anthropic_api_key:\n",
        "    try:\n",
        "        # Use the Anthropic connector to add the service\n",
        "        anthropic_chat_service = Anthropic_Connector(\n",
        "            ai_model_id=anthropic_model_name,\n",
        "            api_key=anthropic_api_key,\n",
        "            service_id=anthropic_service_id,\n",
        "        )\n",
        "        # Add the chat service to the kernel\n",
        "        kernel.add_service(anthropic_chat_service)\n",
        "\n",
        "        print(f\"'{anthropic_model_name}' (service_id: {anthropic_service_id}) added to the kernel as a chat service.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding Anthropic service '{anthropic_model_name}': {e}\")\n",
        "        print(\"Anthropic service not added. Please check your ANTHROPIC_API_KEY in Colab secrets and the semantic-kernel version compatibility.\")\n",
        "else:\n",
        "    if not Anthropic_Connector:\n",
        "        print(\"Anthropic connector class not available due to import failure.\")\n",
        "    else:\n",
        "        print(\"Anthropic API key not found in Colab secrets. Anthropic service not added.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4gk8WJEQSwz",
        "outputId": "3b5e6ef0-7a78-4b46-acd0-c59e0465e0e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported AnthropicChatCompletion from semantic_kernel.connectors.ai.anthropic\n",
            "'claude-opus-4-1-20250805' (service_id: anthropic_service) added to the kernel as a chat service.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Evaluation\n"
      ],
      "metadata": {
        "id": "m8ppWS2ge32I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "import pandas as pd\n",
        "import semantic_kernel as sk\n",
        "import traceback # Import traceback to get stack traces\n",
        "from semantic_kernel.contents.chat_history import ChatHistory # Import ChatHistory explicitly\n",
        "from semantic_kernel.connectors.ai.anthropic import AnthropicChatPromptExecutionSettings\n",
        "\n",
        "\n",
        "# Define the asynchronous function for Anthropic processing with the LLM judge prompt\n",
        "async def judge_with_anthropic(original_note: str, gpt_output: str) -> str:\n",
        "    \"\"\"Processes the GPT-4o output using the Anthropic model with the LLM judge prompt.\"\"\"\n",
        "    print(\"Processing output with Anthropic (LLM Judge)...\")\n",
        "\n",
        "    # Assume llm_judge_prompt, kernel, and anthropic_service_id are available from previous cells\n",
        "    if 'llm_judge_prompt' not in globals() or llm_judge_prompt is None:\n",
        "         return \"Error: LLM judge prompt not loaded. Please run cell 50f1d66e first.\"\n",
        "    if 'kernel' not in globals() or not isinstance(kernel, sk.Kernel):\n",
        "         return \"Error processing with Anthropic: Semantic Kernel not initialized.\"\n",
        "    if 'anthropic_service_id' not in globals():\n",
        "         return \"Error processing with Anthropic: Anthropic service ID not initialized.\"\n",
        "\n",
        "    prompt_content = f\"{llm_judge_prompt}\\n\\nOriginal Medical Note:\\n{original_note}\\n\\nOutput to Evaluate (from GPT-4o):\\n{gpt_output}\\n\\nEvaluation Output (JSON):\\n\"\n",
        "\n",
        "    try:\n",
        "        anthropic_service = kernel.get_service(anthropic_service_id)\n",
        "        if anthropic_service:\n",
        "            chat_history = ChatHistory()\n",
        "            chat_history.add_system_message(\"You are an expert medical text extraction evaluator. Review the provided original note and the extracted output, then provide a structured JSON evaluation.\")\n",
        "            chat_history.add_user_message(prompt_content)\n",
        "\n",
        "            execution_settings = AnthropicChatPromptExecutionSettings()\n",
        "            if hasattr(anthropic_service, 'get_chat_message_content'):\n",
        "                anthropic_output = await anthropic_service.get_chat_message_content(chat_history, settings=execution_settings)\n",
        "                print(\"Anthropic processing successful.\")\n",
        "                return str(anthropic_output)\n",
        "            elif hasattr(anthropic_service, 'generate_text'):\n",
        "                 print(\"Warning: Using generate_text for Anthropic service, but it might be a chat model.\")\n",
        "                 anthropic_output = await anthropic_service.generate_text(chat_history.messages_to_prompt())\n",
        "                 print(\"Anthropic processing successful (using generate_text).\")\n",
        "                 return str(anthropic_output)\n",
        "            else:\n",
        "                 # This should not happen if the service is added correctly, but good for robustness\n",
        "                 error_msg = f\"Service '{anthropic_service_id}' does not have expected generation method (get_chat_message_content or generate_text).\"\n",
        "                 print(error_msg)\n",
        "                 return error_msg\n",
        "\n",
        "        else:\n",
        "            return f\"Error processing with Anthropic: Service '{anthropic_service_id}' not found in kernel.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Anthropic processing: {e}\")\n",
        "        # Print the traceback for unexpected errors\n",
        "        traceback_str = traceback.format_exc()\n",
        "        print(f\"Traceback:\\n{traceback_str}\")\n",
        "        return f\"Error during Anthropic processing: {e}\\nTraceback:\\n{traceback_str}\"\n",
        "\n",
        "\n",
        "# --- Process GPT-4o Outputs with Anthropic LLM Judge ---\n",
        "print(\"\\n--- Running Anthropic LLM Judge on GPT-4o Outputs ---\")\n",
        "\n",
        "# Ensure result_list is available from previous processing step\n",
        "if 'result_list' not in globals() or not isinstance(result_list, list):\n",
        "    print(\"Error: 'result_list' not found or not a list. Please run the processing cell (ac3ab4b2) first.\")\n",
        "    result_list = [] # Initialize as empty list to avoid further errors\n",
        "\n",
        "anthropic_judge_results = []\n",
        "\n",
        "async def evaluate_outputs_with_anthropic(results):\n",
        "    evaluated_count = 0\n",
        "    for i, result_data in enumerate(results):\n",
        "        evaluated_count += 1\n",
        "        print(f\"\\n--- Evaluating Output for Note {i+1}/{len(results)} ---\")\n",
        "        original_note = result_data.get(\"original_note\", \"N/A\")\n",
        "        gpt_output = result_data.get(\"gpt_output\", \"N/A\")\n",
        "\n",
        "        judge_output = await judge_with_anthropic(original_note, gpt_output)\n",
        "\n",
        "        anthropic_judge_results.append({\n",
        "            \"note_index\": i + 1,\n",
        "            \"original_note\": original_note,\n",
        "            \"gpt_output\": gpt_output[:200],\n",
        "            \"anthropic_judge_raw_output\": judge_output,\n",
        "            \"anthropic_judge_parsed_json\": None\n",
        "        })\n",
        "        print(f\"Finished evaluating Output for Note {i+1}. Total evaluated: {evaluated_count}\")\n",
        "    return anthropic_judge_results # Return the list of judge results\n",
        "\n",
        "# Run the asynchronous evaluation\n",
        "evaluated_results = await evaluate_outputs_with_anthropic(result_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BjDKPuKWxXJ",
        "outputId": "2c3d9216-baf3-4b6d-dd81-ef273f1e1bac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Anthropic LLM Judge on GPT-4o Outputs ---\n",
            "\n",
            "--- Evaluating Output for Note 1/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 1. Total evaluated: 1\n",
            "\n",
            "--- Evaluating Output for Note 2/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 2. Total evaluated: 2\n",
            "\n",
            "--- Evaluating Output for Note 3/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 3. Total evaluated: 3\n",
            "\n",
            "--- Evaluating Output for Note 4/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 4. Total evaluated: 4\n",
            "\n",
            "--- Evaluating Output for Note 5/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 5. Total evaluated: 5\n",
            "\n",
            "--- Evaluating Output for Note 6/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 6. Total evaluated: 6\n",
            "\n",
            "--- Evaluating Output for Note 7/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 7. Total evaluated: 7\n",
            "\n",
            "--- Evaluating Output for Note 8/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 8. Total evaluated: 8\n",
            "\n",
            "--- Evaluating Output for Note 9/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 9. Total evaluated: 9\n",
            "\n",
            "--- Evaluating Output for Note 10/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 10. Total evaluated: 10\n",
            "\n",
            "--- Evaluating Output for Note 11/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 11. Total evaluated: 11\n",
            "\n",
            "--- Evaluating Output for Note 12/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 12. Total evaluated: 12\n",
            "\n",
            "--- Evaluating Output for Note 13/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 13. Total evaluated: 13\n",
            "\n",
            "--- Evaluating Output for Note 14/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 14. Total evaluated: 14\n",
            "\n",
            "--- Evaluating Output for Note 15/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 15. Total evaluated: 15\n",
            "\n",
            "--- Evaluating Output for Note 16/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 16. Total evaluated: 16\n",
            "\n",
            "--- Evaluating Output for Note 17/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 17. Total evaluated: 17\n",
            "\n",
            "--- Evaluating Output for Note 18/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 18. Total evaluated: 18\n",
            "\n",
            "--- Evaluating Output for Note 19/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 19. Total evaluated: 19\n",
            "\n",
            "--- Evaluating Output for Note 20/20 ---\n",
            "Processing output with Anthropic (LLM Judge)...\n",
            "Finished evaluating Output for Note 20. Total evaluated: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50f1d66e",
        "outputId": "e33293ee-e9e5-45ed-f5b4-e7e765dfaeac"
      },
      "source": [
        "import semantic_kernel as sk\n",
        "import asyncio\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Assume kernel and anthropic_service_id are initialized and available from previous cells.\n",
        "# Assumes df is loaded and available.\n",
        "\n",
        "\n",
        "# Specify the path to the LLM judge prompt file in Google Drive\n",
        "llm_judge_prompt_file_path = '/content/llm_judge_prompt.md'\n",
        "\n",
        "# Read the LLM judge prompt from the file\n",
        "llm_judge_prompt = None\n",
        "try:\n",
        "    with open(llm_judge_prompt_file_path, 'r') as f:\n",
        "        llm_judge_prompt = f.read()\n",
        "    print(f\"LLM judge prompt read successfully from {llm_judge_prompt_file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The LLM judge prompt file was not found at {llm_judge_prompt_file_path}\")\n",
        "    llm_judge_prompt = None # Set prompt to None if file not found\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the LLM judge prompt file: {e}\")\n",
        "    llm_judge_prompt = None # Set prompt to None if error occurspr\n",
        "\n",
        "\n",
        "print(\"LLM judge prompt loaded. The judge_with_anthropic function has been moved to the cell below.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The LLM judge prompt file was not found at /content/llm_judge_prompt.md\n",
            "LLM judge prompt loaded. The judge_with_anthropic function has been moved to the cell below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Define the output markdown file path\n",
        "output_markdown_file = \"/content/anthropic_judge_evaluation_summary.md\"\n",
        "\n",
        "print(f\"Exporting Anthropic judge evaluation summary to '{output_markdown_file}'...\")\n",
        "\n",
        "# Check if evaluated_results is available and is a list\n",
        "if 'evaluated_results' in globals() and isinstance(evaluated_results, list):\n",
        "    if evaluated_results:\n",
        "        with open(output_markdown_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"# Anthropic LLM Judge Evaluation Summary\\n\\n\")\n",
        "            f.write(\"This document summarizes the evaluations from the Anthropic LLM Judge for GPT-4o outputs.\\n\\n\")\n",
        "\n",
        "            for i, result_data in enumerate(evaluated_results):\n",
        "                note_index = result_data.get(\"note_index\", i + 1)\n",
        "\n",
        "                # Get the full original_note and relevant judge results\n",
        "                full_original_note = result_data.get(\"original_note\")\n",
        "                raw_judge_output = result_data.get(\"anthropic_judge_raw_output\", \"N/A\")\n",
        "                parsed_judge_json = result_data.get(\"anthropic_judge_parsed_json\")\n",
        "\n",
        "                # Handle potentially missing or empty notes for display\n",
        "                if full_original_note is None or full_original_note.strip() == \"\":\n",
        "                    full_original_note_display = \"[Original note is missing or empty]\"\n",
        "                else:\n",
        "                    full_original_note_display = full_original_note.strip()\n",
        "\n",
        "                # Add separator between notes (except before the first one)\n",
        "                if i > 0:\n",
        "                    f.write(\"\\n---\\n\\n\")\n",
        "\n",
        "                f.write(f\"## Note {note_index}\\n\\n\")\n",
        "\n",
        "                # Present the entire original note\n",
        "                f.write(\"### Original Medical Note\\n\\n\")\n",
        "                f.write(f\"```\\n{full_original_note_display}\\n```\\n\\n\")\n",
        "\n",
        "                # Present the Anthropic LLM Judge Output Summary\n",
        "                f.write(\"### Anthropic LLM Judge Evaluation\\n\\n\")\n",
        "\n",
        "                if parsed_judge_json and isinstance(parsed_judge_json, dict):\n",
        "                    f.write(\"#### Evaluation Results\\n\\n\")\n",
        "\n",
        "                    # Create a cleaner table format\n",
        "                    evaluation_items = []\n",
        "\n",
        "                    # Add key fields in a logical order\n",
        "                    field_mappings = {\n",
        "                        \"score\": \"Overall Score\",\n",
        "                        \"validation_status\": \"Validation Status\",\n",
        "                        \"critique_summary\": \"Summary\",\n",
        "                        \"specific_issues\": \"Specific Issues\",\n",
        "                        \"missing_fields\": \"Missing Fields\",\n",
        "                        \"accuracy_assessment\": \"Accuracy Assessment\",\n",
        "                        \"completeness_score\": \"Completeness Score\"\n",
        "                    }\n",
        "\n",
        "                    for key, display_name in field_mappings.items():\n",
        "                        if key in parsed_judge_json:\n",
        "                            value = parsed_judge_json[key]\n",
        "\n",
        "                            # Format the value appropriately\n",
        "                            if isinstance(value, list):\n",
        "                                if value:  # Non-empty list\n",
        "                                    formatted_value = \"• \" + \"<br>• \".join(str(item) for item in value)\n",
        "                                else:\n",
        "                                    formatted_value = \"None identified\"\n",
        "                            elif isinstance(value, dict):\n",
        "                                formatted_value = json.dumps(value, indent=2)\n",
        "                            else:\n",
        "                                formatted_value = str(value)\n",
        "\n",
        "                            evaluation_items.append([display_name, formatted_value])\n",
        "\n",
        "                    # Add any remaining fields not in the mappings\n",
        "                    for key, value in parsed_judge_json.items():\n",
        "                        if key not in field_mappings:\n",
        "                            display_name = key.replace(\"_\", \" \").title()\n",
        "                            if isinstance(value, list):\n",
        "                                if value:\n",
        "                                    formatted_value = \"• \" + \"<br>• \".join(str(item) for item in value)\n",
        "                                else:\n",
        "                                    formatted_value = \"None\"\n",
        "                            elif isinstance(value, dict):\n",
        "                                formatted_value = json.dumps(value, indent=2)\n",
        "                            else:\n",
        "                                formatted_value = str(value)\n",
        "                            evaluation_items.append([display_name, formatted_value])\n",
        "\n",
        "                    if evaluation_items:\n",
        "                        # Create markdown table\n",
        "                        f.write(\"| Field | Value |\\n\")\n",
        "                        f.write(\"|-------|-------|\\n\")\n",
        "                        for field, value in evaluation_items:\n",
        "                            # Escape pipes in the value to prevent table formatting issues\n",
        "                            escaped_value = str(value).replace(\"|\", \"\\\\|\").replace(\"\\n\", \"<br>\")\n",
        "                            f.write(f\"| {field} | {escaped_value} |\\n\")\n",
        "                        f.write(\"\\n\")\n",
        "                    else:\n",
        "                        f.write(\"*No evaluation data available*\\n\\n\")\n",
        "\n",
        "                    # If there are additional fields, show the complete JSON\n",
        "                    if len(parsed_judge_json) > len(evaluation_items):\n",
        "                        f.write(\"#### Complete Evaluation Data\\n\\n\")\n",
        "                        f.write(\"```json\\n\")\n",
        "                        f.write(json.dumps(parsed_judge_json, indent=2, ensure_ascii=False))\n",
        "                        f.write(\"\\n```\\n\\n\")\n",
        "\n",
        "                else:\n",
        "                    f.write(\"#### Raw Evaluation Output\\n\\n\")\n",
        "                    if raw_judge_output and raw_judge_output != \"N/A\":\n",
        "                        f.write(\"```json\\n\")\n",
        "                        f.write(str(raw_judge_output))\n",
        "                        f.write(\"\\n```\\n\\n\")\n",
        "                    else:\n",
        "                        f.write(\"*No evaluation output available*\\n\\n\")\n",
        "\n",
        "            # Final separator\n",
        "            f.write(\"\\n---\\n\\n\")\n",
        "            f.write(f\"*Report generated with {len(evaluated_results)} evaluations*\\n\")\n",
        "            print(f\"Evaluation summary exported successfully to '{output_markdown_file}'\")\n",
        "\n",
        "    else:\n",
        "        print(\"The 'evaluated_results' list is empty. No results to export.\")\n",
        "else:\n",
        "    print(\"Error: 'evaluated_results' not found or not a list. Please run the evaluation cell first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haVV_7_t0jxM",
        "outputId": "a7cc2283-64bb-4c5d-9582-1186e2dabd1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting Anthropic judge evaluation summary to '/content/anthropic_judge_evaluation_summary.md'...\n",
            "Evaluation summary exported successfully to '/content/anthropic_judge_evaluation_summary.md'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstrating how validation with Pydantic would work"
      ],
      "metadata": {
        "id": "l1Yaiji9m8fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional, Dict, Any, Union, Literal\n",
        "from pydantic import BaseModel, Field, field_validator # Import field_validator instead of validator\n",
        "import re\n",
        "\n",
        "# Define Pydantic models corresponding to the JSON schema structure\n",
        "\n",
        "class Condition(BaseModel):\n",
        "    snomed_code: Optional[str] = Field(None, description=\"SNOMED CT code for the condition\")\n",
        "    snomed_term: Optional[str] = Field(None, description=\"SNOMED CT term for the condition\")\n",
        "\n",
        "class Diagnosis(BaseModel):\n",
        "    condition: Condition\n",
        "    status: Optional[str] = Field(None, description=\"Status of the diagnosis (e.g., 'active', 'resolved', 'suspected')\")\n",
        "    diagnosis_date: Optional[str] = Field(None, description=\"Date of diagnosis or relative time (e.g., 'YYYY-MM-DD', 'YYYY', 'X years ago')\")\n",
        "    approx_diagnosis_date: Optional[str] = Field(None, description=\"Approximate date of diagnosis if specific date is not available\")\n",
        "    approx_onset: Optional[str] = Field(None, description=\"Approximate onset of the condition if inferrable\")\n",
        "    is_type2_diabetes: Optional[bool] = Field(None, description=\"Indicates if the diagnosis is Type 2 Diabetes\")\n",
        "    notes: Optional[str] = Field(None, description=\"Additional notes about the diagnosis\")\n",
        "\n",
        "    @field_validator('status')\n",
        "    @classmethod\n",
        "    def validate_status(cls, v):\n",
        "        if v is not None and v not in [\"active\", \"resolved\", \"suspected\", \"inactive\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid diagnosis status\")\n",
        "        return v\n",
        "\n",
        "    @field_validator('diagnosis_date')\n",
        "    @classmethod\n",
        "    def validate_diagnosis_date(cls, v):\n",
        "        if v is not None and not re.fullmatch(r\"^(\\d{4}-\\d{2}-\\d{2}|\\d{4}|.*ago.*)?$\", v):\n",
        "            raise ValueError(\"Invalid diagnosis_date format\")\n",
        "        return v\n",
        "\n",
        "\n",
        "class RecordMetadata(BaseModel):\n",
        "    patient_name: str = Field(..., min_length=1, description=\"Full name of the patient\")\n",
        "    medical_record_number: str = Field(..., min_length=1, description=\"Unique medical record identifier\")\n",
        "    visit_type: Optional[str] = Field(None, description=\"Type of medical visit\")\n",
        "\n",
        "    @field_validator('visit_type')\n",
        "    @classmethod\n",
        "    def validate_visit_type(cls, v):\n",
        "        if v is not None and v not in [\"follow-up\", \"initial consultation\", \"telehealth\", \"emergency\", \"routine check-up\"]:\n",
        "            raise ValueError(\"Invalid visit_type\")\n",
        "        return v\n",
        "\n",
        "class SocioeconomicIndicators(BaseModel):\n",
        "    occupation: Optional[str] = Field(None, description=\"Patient occupation\")\n",
        "    insurance: Optional[str] = Field(None, description=\"Insurance status or type\")\n",
        "    other: Optional[str] = Field(None, description=\"Other socioeconomic indicators\")\n",
        "\n",
        "class Demographics(BaseModel):\n",
        "    age_years: int = Field(..., ge=0, le=150, description=\"Patient age in years\") # Changed field name\n",
        "    sex: str = Field(..., description=\"Patient gender\") # Changed field name\n",
        "    race_ethnicity: Optional[str] = Field(None, description=\"Patient race/ethnicity if specified\")\n",
        "    socioeconomic_indicators: Optional[SocioeconomicIndicators] = None\n",
        "\n",
        "    @field_validator('sex') # Updated validator field\n",
        "    @classmethod\n",
        "    def validate_sex(cls, v):\n",
        "        if v not in [\"male\", \"female\", \"other\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid sex\")\n",
        "        return v\n",
        "\n",
        "class Medication(BaseModel):\n",
        "    drug_name: str = Field(..., min_length=1, description=\"Medication name\")\n",
        "    dosage: str = Field(..., description=\"Dosage with units\")\n",
        "    frequency: str = Field(..., description=\"Dosing frequency\")\n",
        "    drug_class: Optional[str] = Field(None, description=\"Drug classification\")\n",
        "    adherence_issues: Optional[str] = Field(None, description=\"Any reported adherence problems\")\n",
        "    is_current: Optional[bool] = Field(None, description=\"Indicates if the medication is currently being taken\")\n",
        "    notes: Optional[str] = Field(None, description=\"Additional notes about the medication\")\n",
        "\n",
        "    @field_validator('dosage')\n",
        "    @classmethod\n",
        "    def validate_dosage(cls, v):\n",
        "        if not re.fullmatch(r\"^\\d+(\\.\\d+)?\\s*(mg|g|mcg|IU|mL|units?).*$\", v):\n",
        "            raise ValueError(\"Invalid dosage format\")\n",
        "        return v\n",
        "\n",
        "    @field_validator('frequency')\n",
        "    @classmethod\n",
        "    def validate_frequency(cls, v):\n",
        "        if v not in [\"daily\", \"BID\", \"TID\", \"QID\", \"weekly\", \"monthly\", \"as needed\", \"PRN\", \"twice daily\", \"three times daily\", \"four times daily\", \"occasional\"]:\n",
        "            raise ValueError(\"Invalid frequency\")\n",
        "        return v\n",
        "\n",
        "    @field_validator('drug_class')\n",
        "    @classmethod\n",
        "    def validate_drug_class(cls, v):\n",
        "        if v is not None and v not in [\n",
        "            \"biguanide\", \"sulfonylurea\", \"DPP-4 inhibitor\", \"GLP-1 agonist\",\n",
        "            \"SGLT2 inhibitor\", \"insulin\", \"ACE inhibitor\", \"ARB\", \"beta blocker\",\n",
        "            \"calcium channel blocker\", \"diuretic\", \"statin\", \"antiplatelet\",\n",
        "            \"vitamin\", \"supplement\", \"other\"\n",
        "        ]:\n",
        "            raise ValueError(\"Invalid drug_class\")\n",
        "        return v\n",
        "\n",
        "class Adherence(BaseModel):\n",
        "    status: str = Field(..., enum=[\"good\", \"moderate\", \"poor\", \"unknown\"])\n",
        "    evidence: Optional[str] = Field(None, description=\"Evidence or notes about adherence\")\n",
        "\n",
        "class Vitals(BaseModel):\n",
        "    blood_pressure: Optional[str] = Field(None, description=\"Blood pressure reading (e.g., '120/80 mmHg')\")\n",
        "    pulse_bpm: Optional[int] = Field(None, description=\"Pulse in beats per minute\")\n",
        "    temperature: Optional[str] = Field(None, description=\"Temperature reading (e.g., '98.6 F')\")\n",
        "\n",
        "class Lab(BaseModel):\n",
        "    test_name: str = Field(..., description=\"Name of the lab test\")\n",
        "    value: Optional[str] = Field(None, description=\"Test result value as string\")\n",
        "    normalized_value: Optional[float] = Field(None, description=\"Normalized numeric value of the test result\")\n",
        "    unit: Optional[str] = Field(None, description=\"Unit of measurement\")\n",
        "    date: Optional[str] = Field(None, description=\"Date of the lab test\")\n",
        "    status: Optional[str] = Field(None, enum=[\"normal\", \"high\", \"low\", \"pending\", \"unknown\"])\n",
        "\n",
        "    @field_validator('status')\n",
        "    @classmethod\n",
        "    def validate_lab_status(cls, v):\n",
        "        if v is not None and v not in [\"normal\", \"high\", \"low\", \"pending\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid lab status\")\n",
        "        return v\n",
        "\n",
        "class Finding(BaseModel):\n",
        "    condition: Condition\n",
        "    status: Optional[str] = Field(None, description=\"Status of the finding (e.g., 'present', 'absent', 'suspected')\")\n",
        "    severity: Optional[str] = Field(None, description=\"Severity of the finding (e.g., 'mild', 'moderate', 'severe')\")\n",
        "    notes: Optional[str] = Field(None, description=\"Additional notes about the finding\")\n",
        "\n",
        "    @field_validator('status')\n",
        "    @classmethod\n",
        "    def validate_finding_status(cls, v):\n",
        "         if v is not None and v not in [\"present\", \"absent\", \"suspected\", \"resolved\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid finding status\")\n",
        "         return v\n",
        "\n",
        "    @field_validator('severity')\n",
        "    @classmethod\n",
        "    def validate_finding_severity(cls, v):\n",
        "         if v is not None and v not in [\"mild\", \"moderate\", \"severe\", \"early\", \"advanced\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid finding severity\")\n",
        "         return v\n",
        "\n",
        "\n",
        "class SubjectReported(BaseModel):\n",
        "    symptoms: List[str] = []\n",
        "    factors: List[str] = [] # e.g., stress, sleep issues\n",
        "\n",
        "class MentalHealth(BaseModel):\n",
        "    stress: Optional[str] = Field(None, enum=[\"present\", \"absent\", \"unknown\"])\n",
        "    notes: Optional[str] = Field(None, description=\"Notes about mental health\")\n",
        "\n",
        "    @field_validator('stress')\n",
        "    @classmethod\n",
        "    def validate_stress(cls, v):\n",
        "        if v is not None and v not in [\"present\", \"absent\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid stress status\")\n",
        "        return v\n",
        "\n",
        "class Sleep(BaseModel):\n",
        "    issue: Optional[str] = Field(None, enum=[\"insomnia\", \"sleep apnea\", \"restless leg syndrome\", \"circadian rhythm disorder\", \"other\", \"absent\", \"unknown\"])\n",
        "    notes: Optional[str] = Field(None, description=\"Notes about sleep issues\")\n",
        "\n",
        "    @field_validator('issue')\n",
        "    @classmethod\n",
        "    def validate_sleep_issue(cls, v):\n",
        "        if v is not None and v not in [\"insomnia\", \"sleep apnea\", \"restless leg syndrome\", \"circadian rhythm disorder\", \"other\", \"absent\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid sleep issue type\")\n",
        "        return v\n",
        "\n",
        "\n",
        "class PhysicalActivity(BaseModel):\n",
        "    notes: Optional[str] = Field(None, description=\"Notes about physical activity level or type\")\n",
        "\n",
        "class Lifestyle(BaseModel):\n",
        "    smoking_status: str = Field(..., enum=[\"current\", \"former\", \"never\", \"unknown\", \"occasional\"])\n",
        "    alcohol_use: Optional[str] = Field(None, enum=[\"none\", \"social\", \"moderate\", \"heavy\", \"occasional\", \"unknown\"])\n",
        "    diet_notes: Optional[str] = Field(None, description=\"Notes about diet or adherence\")\n",
        "\n",
        "    @field_validator('smoking_status')\n",
        "    @classmethod\n",
        "    def validate_smoking_status(cls, v):\n",
        "        if v not in [\"current\", \"former\", \"never\", \"unknown\", \"occasional\"]:\n",
        "            raise ValueError(\"Invalid smoking status\")\n",
        "        return v\n",
        "\n",
        "    @field_validator('alcohol_use')\n",
        "    @classmethod\n",
        "    def validate_alcohol_use(cls, v):\n",
        "        if v is not None and v not in [\"none\", \"social\", \"moderate\", \"heavy\", \"occasional\", \"unknown\"]:\n",
        "            raise ValueError(\"Invalid alcohol use\")\n",
        "        return v\n",
        "\n",
        "\n",
        "class MajorDiabeticComplication(BaseModel):\n",
        "    complication: Condition\n",
        "    had_complication: bool = Field(..., description=\"Indicates if the patient had this specific major complication\")\n",
        "\n",
        "class MajorDiabeticComplicationsSummary(BaseModel):\n",
        "     had_complication: bool = Field(..., description=\"Overall indicator if the patient had any major diabetic complication\")\n",
        "     complications: List[MajorDiabeticComplication] = []\n",
        "\n",
        "\n",
        "class Negation(BaseModel):\n",
        "    finding_or_symptom: str = Field(..., description=\"Finding or symptom that was negated\")\n",
        "    evidence: Optional[str] = Field(None, description=\"Evidence for the negation\")\n",
        "\n",
        "class Uncertainty(BaseModel):\n",
        "    finding_or_symptom: str = Field(..., description=\"Finding or symptom with uncertainty\")\n",
        "    evidence: Optional[str] = Field(None, description=\"Evidence for the uncertainty\")\n",
        "\n",
        "class IgnoredNonclinical(BaseModel):\n",
        "     text: str = Field(..., description=\"Text that was ignored as non-clinical\")\n",
        "     reason: Optional[str] = Field(None, description=\"Reason for ignoring the text\")\n",
        "\n",
        "\n",
        "class PlanNextSteps(BaseModel):\n",
        "    step: str = Field(..., description=\"A planned next step for patient care\")\n",
        "\n",
        "\n",
        "class MedicalRecordExtractionSchema(BaseModel): # Renamed the main model for clarity\n",
        "    \"\"\"Schema for extracted medical record information focusing on Type 2 Diabetes patients\"\"\"\n",
        "    record_metadata: RecordMetadata\n",
        "    demographics: Demographics\n",
        "    diagnoses: List[Diagnosis] = [] # Changed field name and type\n",
        "    comorbidities: List[Condition] = [] # Changed field type (assuming comorbidities are conditions)\n",
        "    medications: List[Medication] = []\n",
        "    adherence: Optional[Adherence] = None # Added Adherence model\n",
        "    vitals: Optional[Vitals] = None # Added Vitals model\n",
        "    labs: List[Lab] = [] # Changed field name\n",
        "    findings: List[Finding] = [] # Added Findings model\n",
        "    subject_reported: Optional[SubjectReported] = None # Added SubjectReported model\n",
        "    mental_health: Optional[MentalHealth] = None # Added MentalHealth model\n",
        "    sleep: Optional[Sleep] = None # Added Sleep model\n",
        "    physical_activity: Optional[PhysicalActivity] = None # Added PhysicalActivity model\n",
        "    lifestyle: Optional[Lifestyle] = None # Added Lifestyle model\n",
        "    major_diabetic_complication: MajorDiabeticComplicationsSummary # Changed field name and type\n",
        "    negations: List[Negation] = [] # Added Negations model\n",
        "    uncertainties: List[Uncertainty] = [] # Added Uncertainties model\n",
        "    ignored_nonclinical: List[IgnoredNonclinical] = [] # Added IgnoredNonclinical model\n",
        "    plan_next_steps: List[PlanNextSteps] = [] # Changed field name and type\n",
        "\n",
        "\n",
        "# Example of a valid data structure (as a dictionary) based on the new schema\n",
        "valid_sample_output_data = {\n",
        "  \"record_metadata\": {\n",
        "    \"patient_name\": \"John Smith\",\n",
        "    \"medical_record_number\": \"1234\"\n",
        "  },\n",
        "  \"demographics\": {\n",
        "    \"age_years\": 58,\n",
        "    \"sex\": \"male\",\n",
        "    \"race_ethnicity\": None,\n",
        "    \"socioeconomic_indicators\": None\n",
        "  },\n",
        "  \"diagnoses\": [\n",
        "    {\n",
        "      \"condition\": {\n",
        "        \"snomed_code\": None,\n",
        "        \"snomed_term\": \"Type 2 diabetes mellitus\"\n",
        "      },\n",
        "      \"status\": \"active\",\n",
        "      \"diagnosis_date\": None,\n",
        "      \"approx_diagnosis_date\": None,\n",
        "      \"approx_onset\": \"3 years ago\",\n",
        "      \"is_type2_diabetes\": True,\n",
        "      \"notes\": \"Well-controlled\"\n",
        "    },\n",
        "     {\n",
        "      \"condition\": {\n",
        "        \"snomed_code\": \"38341003\", # Example SNOMED code for Hypertension\n",
        "        \"snomed_term\": \"Hypertension\"\n",
        "      },\n",
        "      \"status\": \"active\",\n",
        "      \"diagnosis_date\": None,\n",
        "      \"approx_diagnosis_date\": None,\n",
        "      \"approx_onset\": None,\n",
        "      \"is_type2_diabetes\": False,\n",
        "      \"notes\": \"Managed with medication\"\n",
        "    }\n",
        "  ],\n",
        "  \"comorbidities\": [\n",
        "    {\n",
        "      \"snomed_code\": \"38341003\",\n",
        "      \"snomed_term\": \"Hypertension\"\n",
        "    },\n",
        "     {\n",
        "      \"snomed_code\": \"114490001\", # Example SNOMED code for Hyperlipidemia\n",
        "      \"snomed_term\": \"Hyperlipidemia\"\n",
        "    }\n",
        "  ],\n",
        "  \"medications\": [\n",
        "    {\n",
        "      \"drug_name\": \"Metformin\",\n",
        "      \"dosage\": \"1000 mg\",\n",
        "      \"frequency\": \"daily\",\n",
        "      \"drug_class\": \"biguanide\",\n",
        "      \"adherence_issues\": \"none\",\n",
        "      \"is_current\": True,\n",
        "      \"notes\": None\n",
        "    },\n",
        "    {\n",
        "      \"drug_name\": \"Lisinopril\",\n",
        "      \"dosage\": \"10 mg\",\n",
        "      \"frequency\": \"daily\",\n",
        "      \"drug_class\": \"ACE inhibitor\",\n",
        "      \"adherence_issues\": \"none\",\n",
        "      \"is_current\": True,\n",
        "      \"notes\": None\n",
        "    }\n",
        "  ],\n",
        "  \"adherence\": {\n",
        "    \"status\": \"good\",\n",
        "    \"evidence\": \"Patient reports taking all medications as prescribed\"\n",
        "  },\n",
        "  \"vitals\": {\n",
        "    \"blood_pressure\": \"130/85 mmHg\",\n",
        "    \"pulse_bpm\": 72,\n",
        "    \"temperature\": None\n",
        "  },\n",
        "  \"labs\": [\n",
        "    {\n",
        "      \"test_name\": \"A1C\",\n",
        "      \"value\": \"7.2%\",\n",
        "      \"normalized_value\": 7.2,\n",
        "      \"unit\": \"%\",\n",
        "      \"date\": \"2024-07-01\",\n",
        "      \"status\": \"high\"\n",
        "    },\n",
        "     {\n",
        "      \"test_name\": \"LDL Cholesterol\",\n",
        "      \"value\": \"110 mg/dL\",\n",
        "      \"normalized_value\": 110.0,\n",
        "      \"unit\": \"mg/dL\",\n",
        "      \"date\": \"2024-07-01\",\n",
        "      \"status\": \"normal\"\n",
        "    }\n",
        "  ],\n",
        "  \"findings\": [\n",
        "    {\n",
        "        \"condition\": {\n",
        "            \"snomed_code\": None,\n",
        "            \"snomed_term\": \"Peripheral neuropathy\"\n",
        "        },\n",
        "        \"status\": \"present\",\n",
        "        \"severity\": \"mild\",\n",
        "        \"notes\": \"Reported tingling in feet\"\n",
        "    }\n",
        "  ],\n",
        "  \"subject_reported\": {\n",
        "    \"symptoms\": [\"fatigue\", \"increased thirst\"],\n",
        "    \"factors\": [\"stress from work\"]\n",
        "  },\n",
        "  \"mental_health\": {\n",
        "    \"stress\": \"present\",\n",
        "    \"notes\": \"Patient reports high stress levels due to job demands\"\n",
        "  },\n",
        "  \"sleep\": {\n",
        "    \"issue\": \"insomnia\",\n",
        "    \"notes\": \"Difficulty falling asleep\"\n",
        "  },\n",
        "  \"physical_activity\": {\n",
        "    \"notes\": \"Minimal exercise since winter started\"\n",
        "  },\n",
        "  \"lifestyle\": {\n",
        "    \"smoking_status\": \"never\",\n",
        "    \"alcohol_use\": \"social\",\n",
        "    \"diet_notes\": \"Reports trying to eat healthier\",\n",
        "    \"medication_compliance\": \"good\"\n",
        "  },\n",
        "  \"major_diabetic_complication\": {\n",
        "     \"had_complication\": False,\n",
        "     \"complications\": []\n",
        "  },\n",
        "  \"negations\": [\n",
        "    {\n",
        "        \"finding_or_symptom\": \"chest pain\",\n",
        "        \"evidence\": \"Patient denies chest pain\"\n",
        "    }\n",
        "  ],\n",
        "  \"uncertainties\": [],\n",
        "  \"ignored_nonclinical\": [\n",
        "    {\n",
        "        \"text\": \"He mentions his pet dog, a golden retriever.\",\n",
        "        \"reason\": \"Non-clinical personal information\"\n",
        "    }\n",
        "  ],\n",
        "  \"plan_next_steps\": [\n",
        "    {\n",
        "        \"step\": \"Encourage more physical activity, potentially indoors\"\n",
        "    },\n",
        "     {\n",
        "        \"step\": \"Order new labs to monitor lipid profile and blood glucose control\"\n",
        "    },\n",
        "     {\n",
        "        \"step\": \"Discuss possible addition of medication for better glycemic management if needed\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "# Example of an invalid data structure (missing required field in nested model)\n",
        "invalid_sample_output_data = {\n",
        "  \"record_metadata\": {\n",
        "    \"patient_name\": \"Jane Doe\",\n",
        "    \"medical_record_number\": \"5678\"\n",
        "    # visit_type is optional, so its absence is fine\n",
        "  },\n",
        "  \"demographics\": {\n",
        "    \"age_years\": 55,\n",
        "    # sex is required but missing\n",
        "  },\n",
        "  \"diagnoses\": [],\n",
        "  \"comorbidities\": [],\n",
        "  \"medications\": [],\n",
        "  \"laboratory_values\": {},\n",
        "  \"clinical_findings\": {},\n",
        "  \"major_diabetic_complication\": {\n",
        "     \"had_complication\": False,\n",
        "     \"complications\": []\n",
        "  },\n",
        "  \"negations\": [],\n",
        "  \"uncertainties\": [],\n",
        "  \"ignored_nonclinical\": [],\n",
        "  \"plan_next_steps\": []\n",
        "  # diabetes_status, patient_reported_factors, treatment_plan are required but missing at top level\n",
        "}\n",
        "\n",
        "\n",
        "# Validate the sample outputs using Pydantic\n",
        "try:\n",
        "    valid_output_model = MedicalRecordExtractionSchema(**valid_sample_output_data)\n",
        "    print(\"\\nValid sample output is valid according to the Pydantic schema.\")\n",
        "    # You can access validated data as attributes:\n",
        "    # print(valid_output_model.record_metadata.patient_name)\n",
        "except Exception as e:\n",
        "    print(f\"\\nValid sample output validation failed: {e}\")\n",
        "\n",
        "try:\n",
        "    invalid_output_model = MedicalRecordExtractionSchema(**invalid_sample_output_data)\n",
        "    print(\"\\nInvalid sample output is valid according to the Pydantic schema (unexpected).\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nInvalid sample output validation failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0sUcGRtcLI",
        "outputId": "5075c9d8-cd2a-4e3a-f2f7-b2b83647e730"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valid sample output is valid according to the Pydantic schema.\n",
            "\n",
            "Invalid sample output validation failed: 1 validation error for MedicalRecordExtractionSchema\n",
            "demographics.sex\n",
            "  Field required [type=missing, input_value={'age_years': 55}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **The cell above should produce an \"validation failed\" error to show what would happen if an invalid output was passed to it 😀**\n",
        "\n"
      ],
      "metadata": {
        "id": "JJVQCwqRWRKb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "295f2b0f",
        "outputId": "892d2230-7af4-4617-c7cc-0156c7a7e15a"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from pydantic import ValidationError\n",
        "\n",
        "# Assuming MedicalRecordExtractionSchema is defined in a previous cell (e.g., cell 5H0sUcGRtcLI)\n",
        "# Make sure the cell defining the schema has been executed before running this cell.\n",
        "\n",
        "output_dir = \"extracted_outputs\"\n",
        "validated_outputs = []\n",
        "validation_errors = {}\n",
        "\n",
        "print(f\"Loading JSON outputs from '{output_dir}' and validating against Pydantic schema...\")\n",
        "\n",
        "# Iterate through files in the output directory\n",
        "if os.path.exists(output_dir):\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith(\"_gpt4o_output.json\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            print(f\"\\nValidating file: {filename}\")\n",
        "\n",
        "            try:\n",
        "                # Load the JSON data from the file\n",
        "                with open(file_path, 'r') as f:\n",
        "                    extracted_data = json.load(f)\n",
        "\n",
        "                # Validate the loaded data using the Pydantic schema\n",
        "                validated_model = MedicalRecordExtractionSchema(**extracted_data)\n",
        "                validated_outputs.append({\"filename\": filename, \"data\": validated_model})\n",
        "                print(f\"Validation successful for {filename}\")\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: File not found at {file_path}\")\n",
        "                validation_errors[filename] = f\"File not found: {file_path}\"\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON from {filename}: {e}\")\n",
        "                validation_errors[filename] = f\"JSON Decode Error: {e}\"\n",
        "            except ValidationError as e:\n",
        "                print(f\"Pydantic Validation Error for {filename}:\\n{e}\")\n",
        "                validation_errors[filename] = f\"Validation Error: {e}\"\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred while processing {filename}: {e}\")\n",
        "                validation_errors[filename] = f\"Unexpected Error: {e}\"\n",
        "else:\n",
        "    print(f\"Output directory '{output_dir}' not found. Please ensure the previous processing step was successful.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Validation Summary ---\")\n",
        "print(f\"Successfully validated {len(validated_outputs)} files.\")\n",
        "if validation_errors:\n",
        "    print(f\"Validation failed for {len(validation_errors)} files:\")\n",
        "    for filename, error_msg in validation_errors.items():\n",
        "        print(f\"- {filename}: {error_msg}\")\n",
        "else:\n",
        "    print(\"All processed GPT-4o JSON outputs passed Pydantic validation.\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading JSON outputs from 'extracted_outputs' and validating against Pydantic schema...\n",
            "\n",
            "--- Validation Summary ---\n",
            "Successfully validated 0 files.\n",
            "All processed GPT-4o JSON outputs passed Pydantic validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Output\n",
        "- Model extraction outputs produced above and saved as **`all_extracted_gpt4o_outputs.json`**\n",
        "- Evaluation outputs produced in \"Evaluation\" section above and saved as **`anthropic_judge_evaluation_summary.md`**\n"
      ],
      "metadata": {
        "id": "bDQCLjZje76H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Summary"
      ],
      "metadata": {
        "id": "2pk5A-YRe_XQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Approach\n",
        "\n",
        "1. **Orientation**\n",
        "    - I first briefly reviewed the research literature to look for any clear benchmarks directly aligned with the task at hand. In the short time allotted this produced mixed signals, some suggesting that for NER, encoder only models like BERT (e.g. ClinicalBERT, BioMedBERT, etc.) still outperformed larger, but still relatively small general purpose LLMs like the 7B parameter Llama-2 and Mistral models. Xie et al. also suggest that GPT-4 performance was “poor” on the i2b2 NER task.\n",
        "        - Source: Wu, Jiageng, et al. \"BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text.\" arXiv preprint arXiv:2504.19467 (2025).\n",
        "        - Source: Xie, Qianqian, et al. \"Me-llama: Foundation large language models for medical applications.\" Research square (2024): rs-3.\n",
        "    - I ran a small automated systematic review (n=10) on Elicit that suggested much larger models like LlaMa-65B, and GPT-4 indeed outperformed ClinicalBERT, and BiomedBERT. Ideally, I would have run a 10x larger review, and also closely compared the specific benchmarks mentioned. With automation tools, and a pro account this could also be done fairly hands off in a few hours.\n",
        "    - To decide on a path, I drew on my experience fine-tuning BioBERT a few years back.  That was a lengthy process requiring careful development of a dataset, set up of the training infrastructure, and significant time developing and testing the training code. Based on that experience, and the micro-lit review, I decided that for the purpose of this exercise, it would be fastest and most interesting to look primarily at the most performant off-the-shelf models. To this end I chose to use GPT-4o. OpenAI provides a somewhat simple interface to enable endusers to fine-tune a model without any of the complexity typically required to fine-tune models of this type, though this still requires the non-trivial work of preparing an appropriate dataset.\n",
        "2. **Extraction Approach**\n",
        "    - The information contained in clinical notes is very heterogenous, and different extraction approaches will vary in their applicability for a particular information type. Despite this, LLMs have proven to be broadly applicable to a wide range of information types.\n",
        "    - For this exercise, I chose to use GPT-4o, this comes with some significant trade-offs regarding speed, and hallucination risks. In a real-life scenario I would want to use the fastest, most reliable methods for as much as possible, and only use an LLM for more complex, and difficult to extract elements. I would want to evaluate the model’s performance for each information type. For example in the notebook, you’ll see that I begin by extracting names, gender, age, and medical record numbers using RegEx because on a cursory check of the records, it was clear that these fields followed a very consistent pattern, so it would make more sense to directly extract those instead of risking the model doing something unexpected with them.\n",
        "    - In addition to the attributes provided, there are other pieces of information that could be extracted from the clinical notes, that might be of particular interest to clinical researchers looking at diabetic subjects. I collected a few of these by quickly reviewing some of the clinical research on the topic. Those attributes are listed below, and were incorporated into the extraction prompts.\n",
        "    - Attributes to extract from notes\n",
        "        \n",
        "        ### Patient Demographics & Identification\n",
        "        \n",
        "        - **Record Metadata**\n",
        "            - Patient name\n",
        "            - Medical record number\n",
        "        - **Demographics**\n",
        "            - Race/ethnicity\n",
        "            - Socieconomic class\n",
        "        \n",
        "        ### Clinical Information\n",
        "        \n",
        "        - **Medications**\n",
        "            - Current medications\n",
        "            - Medication adherence\n",
        "        - **Medical History**\n",
        "            - Concomitant diseases\n",
        "            - Clinical findings (SNOMED CT coded)\n",
        "        \n",
        "        ### Disease-Specific Data\n",
        "        \n",
        "        - **Diagnoses**\n",
        "            - Primary disease diagnoses\n",
        "            - Disease diagnosis date\n",
        "            - Approximate disease onset\n",
        "        - **Complications**\n",
        "            - Major diabetic complications (True/False)\n",
        "            - Specific examples: Amputation, kidney damage, skin conditions, retinopathy, nephropathy, neuropathy\n",
        "        \n",
        "        ### Patient-Reported Information\n",
        "        \n",
        "        - **Symptoms & Factors**\n",
        "            - Subject-reported symptoms\n",
        "            - Subject-reported contributing factors\n",
        "        - **Lifestyle & Behavioral Factors**\n",
        "            - Mental health status (including stress levels)\n",
        "            - Sleep patterns\n",
        "            - Physical activity levels\n",
        "            - Lifestyle habits (smoking, alcohol consumption)\n",
        "3. **Model Selection**\n",
        "    - I’ll say directly that I didn’t go through a thorough model selection process. Doing that would have entailed setting up the most promising candidates with an eval dataset, and some well defined performance metrics closely aligned with the downstream application. This was of course not possible, so I choose a model based on instant accessibility (which ruled out some potentially interesting models), and mostly intuition.\n",
        "4. **Model Orchestration**\n",
        "    - There are a few good orchestration options out there, but I’ve used Semantic Kernel from Microsoft on a previous project and had a relatively good experience with it, so I decided it would be sufficient for the task. Semantic Kernel is a rather lightweight framework,  but I probably could have even used something more lightweight, but in the interest of time, I decided to stick with something I knew. Semantic Kernel is well supported, and the development team at Microsoft has been super receptive to the community. Holding regular office hours that I’ve frequently used to learn more about the framework, and ask questions when we needed guidance.\n",
        "5. **Hallucination Mitigation**\n",
        "    - To address hallucinations I choose a few approaches that could be quickly implemented including developing a JSON schema with expected data types. Additionally for some fields, I provide a field called “evidence” for the model to reference exact quotes from the clinical note that support the attribute value selected.\n",
        "    - In the notebook, I show an incomplete example of how Pydantic could be used to validate the model’s JSON outputs (note: the Pydantic structure and JSON schema provided in the prompt are currently not in sync, but with more time you would likely design the desired data model, and derive both Pydantic structure and JSON schema provided in the prompt from the same source). Another reason to use Pydantic is some model APIs and orchestration frameworks directly support passing Pydantic classes, and relieve some of the verification burden from the developer. One would also want to carefully choose appropriate validation criteria for each field, the validation criteria shown in the notebook is mostly just a toy example of what validation could look like. Ideally one could lean on an existing standard like i2b2 to provide a reasonable structure and constraints for the most common information types.\n",
        "    - Lastly it would also be very interesting to explore some of the emerging approaches to uncertainty estimation that could also help us detect, revise, and/or remove LLM outputs that the model is uncertain about. There are a few flavors of approaches ranging from bayesian inference based methods, to ensemble methods, and information theoretic approaches. Some approaches require open weights, but there are some approaches that also applicable on closed-weight models.\n",
        "6. **Evaluation**\n",
        "    - I to perform a LLM-as-a-judge evaluation by using Claude Opus 4.1 to produce a rating  of the correctness of the extraction. I provided the model with a rough rubric by which to evaluate the correctness of the extractions. To reduce the required time, I restrict this eval to a “challenging” subset of the fields related to medication adherence, physical activity, and nutrition. These were chosen because this type of information is especially challenging for typical information retrieval methods to make sense of. Ideally one would also perform a manual assessment where a human would review the quality of the extraction, then we would calculate correlation coefficients between the LLM judge and the human evaluations. Scaling this approach would mean expanding to all fields, looking at a significantly larger dataset, and using multiple human evaluators to enable us to understand the inter-evaluator agreement for different extractions to identify inherently challenging aspects of the task."
      ],
      "metadata": {
        "id": "tLiqVVM-LhaJ"
      }
    }
  ]
}